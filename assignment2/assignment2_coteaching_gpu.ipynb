{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4140ef1c",
   "metadata": {},
   "source": [
    "# Co-Teaching++ (GPU, Forget-Rate Schedule + Dropout/BN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f83eff-a756-4936-849b-349f336f03ba",
   "metadata": {},
   "source": [
    "# 1.导入库并使用GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f54ebb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "import os, random, numpy as np, math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PIN_MEMORY = torch.cuda.is_available()\n",
    "NUM_WORKERS = 0\n",
    "print(\"Device:\", DEVICE)\n",
    "if torch.cuda.is_available(): print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d5a4f0-23cf-4d34-aebe-03e9aeeb335f",
   "metadata": {},
   "source": [
    "# 2.数据加载与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1c4999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); \n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def _infer_hw_c_from_flat_dim(D:int):\n",
    "    s = int(np.sqrt(D) + 1e-8)\n",
    "    if s*s == D: return s, s, 1\n",
    "    if D % 3 == 0:\n",
    "        s3 = int(np.sqrt(D//3) + 1e-8)\n",
    "        if s3*s3*3 == D: return s3, s3, 3\n",
    "    return None, None, None\n",
    "\n",
    "def load_npz(path:str):\n",
    "    d = np.load(path)\n",
    "    Xtr, Str = d[\"Xtr\"], d[\"Str\"]\n",
    "    Xts, Yts = d[\"Xts\"], d[\"Yts\"]\n",
    "    if Xtr.ndim == 4 and Xtr.shape[-1]==3: H,W,C = Xtr.shape[1], Xtr.shape[2], 3\n",
    "    elif Xtr.ndim == 3: H,W,C = Xtr.shape[1], Xtr.shape[2], 1\n",
    "    elif Xtr.ndim == 2:\n",
    "        H,W,C = _infer_hw_c_from_flat_dim(Xtr.shape[1])\n",
    "        if H is None: raise ValueError(\"Cannot infer HWC\")\n",
    "    else: raise ValueError(f\"Bad shape: {Xtr.shape}\")\n",
    "    num_classes = int(max(Str.max(), Yts.max())+1)\n",
    "    return (Xtr, Str, Xts, Yts, (H,W,C), num_classes)\n",
    "\n",
    "class NPZImageDataset(Dataset):\n",
    "    def __init__(self, X, y, shape_hw_c):\n",
    "        X = X.astype(np.float32)\n",
    "        H,W,C = shape_hw_c\n",
    "        if X.ndim == 2:\n",
    "            X = X.reshape(-1,H,W) if C==1 else X.reshape(-1,H,W,C)\n",
    "        if X.max()>1.5: X = X/255.0\n",
    "        if X.ndim == 3: X = X[:,None,:,:]\n",
    "        elif X.ndim == 4: X = np.transpose(X,(0,3,1,2))\n",
    "        X = (X - X.mean())/(X.std()+1e-6)\n",
    "        self.X, self.y = X, y.astype(np.int64)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self,i): return torch.from_numpy(self.X[i]), int(self.y[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a613d9-e21d-4ba4-8412-d1a2c4165293",
   "metadata": {},
   "source": [
    "# 3.定义卷积神经网络 CNN 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "939d3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_BN_Drop(nn.Module):\n",
    "    def __init__(self, in_ch=1, num_classes=10, p_drop=0.4):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(p_drop),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(p_drop),\n",
    "        )\n",
    "        self.adapt = nn.AdaptiveAvgPool2d((7,7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*7*7, 256), nn.ReLU(),\n",
    "            nn.Dropout(p_drop),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = self.adapt(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "def make_model(in_ch, C, p_drop=0.4):\n",
    "    return CNN_BN_Drop(in_ch=in_ch, num_classes=C, p_drop=p_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7646eeee-7918-41b4-93bc-8f26f5e750df",
   "metadata": {},
   "source": [
    "# 4.算法训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b91a513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_indices_by_small_loss(logits, y, keep_ratio):\n",
    "    losses = F.cross_entropy(logits, y, reduction='none')\n",
    "    k = max(1, int(keep_ratio * len(losses)))\n",
    "    return torch.topk(-losses, k=k).indices\n",
    "\n",
    "def coteach_epoch(model1, model2, loader, opt1, opt2, keep_ratio):\n",
    "    model1.train(); model2.train(); total=0.0\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "        l1, l2 = model1(x), model2(x)\n",
    "        idx1 = topk_indices_by_small_loss(l1, y, keep_ratio)\n",
    "        idx2 = topk_indices_by_small_loss(l2, y, keep_ratio)\n",
    "        loss1 = F.cross_entropy(l1[idx2], y[idx2])\n",
    "        loss2 = F.cross_entropy(l2[idx1], y[idx1])\n",
    "        opt1.zero_grad(); loss1.backward(); opt1.step()\n",
    "        opt2.zero_grad(); loss2.backward(); opt2.step()\n",
    "        total += (loss1.item()+loss2.item())/2\n",
    "    return total/len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval(); corr=0; tot=0\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "        pred = model(x).argmax(1)\n",
    "        corr += (pred==y).sum().item(); tot += y.size(0)\n",
    "    return corr/tot\n",
    "\n",
    "def linear_schedule(epoch, max_epoch, final_forget):\n",
    "    return min(final_forget, final_forget * epoch / max(1, max_epoch))\n",
    "\n",
    "def cosine_schedule(epoch, max_epoch, final_forget):\n",
    "    t = epoch / max(1, max_epoch)\n",
    "    return final_forget * (0.5 - 0.5*math.cos(math.pi * t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9990600-737f-47ab-ba47-7482813e644c",
   "metadata": {},
   "source": [
    "# 5.训练配置：带调度的 Co-teaching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0567310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_config_coteach_scheduled(dataset_path, epochs, wd, lr, seed=2025,\n",
    "                                   final_forget=0.6, sched='cosine', p_drop=0.4,\n",
    "                                   warmup_epochs=8):\n",
    "    set_seed(seed)\n",
    "    Xtr, Str, Xts, Yts, hwc, C = load_npz(dataset_path)\n",
    "    tr_idx, va_idx = train_test_split(np.arange(len(Str)), test_size=0.2,\n",
    "                                      stratify=Str, random_state=seed)\n",
    "    tr = NPZImageDataset(Xtr[tr_idx], Str[tr_idx], shape_hw_c=hwc)\n",
    "    va = NPZImageDataset(Xtr[va_idx], Str[va_idx], shape_hw_c=hwc)\n",
    "    ts = NPZImageDataset(Xts, Yts, shape_hw_c=hwc)\n",
    "\n",
    "    tr_loader = DataLoader(tr, batch_size=256, shuffle=True,\n",
    "                           num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "    va_loader = DataLoader(va, batch_size=256, shuffle=False,\n",
    "                           num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "    ts_loader = DataLoader(ts, batch_size=256, shuffle=False,\n",
    "                           num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "    in_ch = hwc[2]\n",
    "    m1 = make_model(in_ch, C, p_drop).to(DEVICE)\n",
    "    m2 = make_model(in_ch, C, p_drop).to(DEVICE)\n",
    "    opt1 = torch.optim.AdamW(m1.parameters(), lr=lr, weight_decay=wd)\n",
    "    opt2 = torch.optim.AdamW(m2.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    # ===== 训练 =====\n",
    "    for ep in range(1, epochs + 1):\n",
    "        if ep <= warmup_epochs:\n",
    "            # 纯 CE 预热\n",
    "            m1.train(); m2.train()\n",
    "            for x, y in tr_loader:\n",
    "                x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "                opt1.zero_grad(set_to_none=True); F.cross_entropy(m1(x), y).backward(); opt1.step()\n",
    "                opt2.zero_grad(set_to_none=True); F.cross_entropy(m2(x), y).backward(); opt2.step()\n",
    "            continue\n",
    "\n",
    "        # 之后进入 Co-Teaching，调度从 warmup 结束后开始\n",
    "        t_ep = ep - warmup_epochs\n",
    "        T_total = max(1, epochs - warmup_epochs)\n",
    "        if sched == 'cosine':\n",
    "            forget = cosine_schedule(t_ep, T_total, final_forget)\n",
    "        else:\n",
    "            forget = linear_schedule(t_ep, T_total, final_forget)\n",
    "\n",
    "        keep_ratio = float(min(1.0, max(0.0, 1.0 - forget)))\n",
    "        coteach_epoch(m1, m2, tr_loader, opt1, opt2, keep_ratio)\n",
    "\n",
    "    # ===== 评估 =====\n",
    "    va_acc = max(evaluate(m1, va_loader), evaluate(m2, va_loader))\n",
    "    ts_acc = max(evaluate(m1, ts_loader), evaluate(m2, ts_loader))\n",
    "    val_loss = 1.0 - va_acc\n",
    "    return val_loss, ts_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a1f206-04cb-44a5-9140-47015554fd8f",
   "metadata": {},
   "source": [
    "# 5.网格调参 + 报告最佳结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d640fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_report_coteach_plus(dataset_path, lr=1e-3, it_values=(500,), wd_values=(1e-4,1e-3,5e-2,1e-2,5e-1,1e-1),\n",
    "                                 seed=42, final_forget=0.6, sched='liner', p_drop=0.4):\n",
    "    print(f\"==== Dataset: {dataset_path} ====\")\n",
    "    print(\"Tuned configs (both orientations):\")\n",
    "    best=None\n",
    "    for it in it_values:\n",
    "        for wd in wd_values:\n",
    "            vloss,tacc = train_config_coteach_scheduled(dataset_path, epochs=it, wd=wd, lr=lr, seed=seed,\n",
    "                                                        final_forget=final_forget, sched=sched, p_drop=p_drop)\n",
    "            print(f\"wd={wd}, it={it} | val_loss={vloss:.4f}, test_acc={tacc*100:.2f}%\")\n",
    "            if (best is None) or (vloss<best[0]-1e-12) or (abs(vloss-best[0])<1e-12 and tacc>best[1]):\n",
    "                best=(vloss,tacc,wd,it)\n",
    "    print(f\"** Best: wd={best[2]}, it={best[3]} | val_loss={best[0]:.4f}, test_acc={best[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "803f2398-a035-4890-b8dd-e0717196ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定你的数据集路径\n",
    "DATASET_1 = \"datasets/FashionMNIST0.3.npz\"\n",
    "DATASET_2 = \"datasets/FashionMNIST0.6.npz\"\n",
    "DATASET_3 = \"datasets/CIFAR.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca1dad-d85c-4bd9-8f64-932c076ccb74",
   "metadata": {},
   "source": [
    "# 调参过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5853302e-a2ae-4ea6-93fe-91ac5c44a313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Dataset: datasets/CIFAR.npz ====\n",
      "Tuned configs (both orientations):\n",
      "wd=0.05, it=300 | val_loss=0.6453, test_acc=50.13%\n",
      "** Best: wd=0.05, it=300 | val_loss=0.6453, test_acc=50.13%\n",
      "==== Dataset: datasets/CIFAR.npz ====\n",
      "Tuned configs (both orientations):\n",
      "wd=0.05, it=300 | val_loss=0.6283, test_acc=51.57%\n",
      "** Best: wd=0.05, it=300 | val_loss=0.6283, test_acc=51.57%\n",
      "==== Dataset: datasets/CIFAR.npz ====\n",
      "Tuned configs (both orientations):\n",
      "wd=0.05, it=300 | val_loss=0.6420, test_acc=52.33%\n",
      "** Best: wd=0.05, it=300 | val_loss=0.6420, test_acc=52.33%\n",
      "==== Dataset: datasets/CIFAR.npz ====\n",
      "Tuned configs (both orientations):\n",
      "wd=0.05, it=300 | val_loss=0.6380, test_acc=45.67%\n",
      "** Best: wd=0.05, it=300 | val_loss=0.6380, test_acc=45.67%\n"
     ]
    }
   ],
   "source": [
    "tune_and_report_coteach_plus(\"datasets/CIFAR.npz\",\n",
    "    lr=3e-4, it_values=(300,), wd_values=(5e-2,),\n",
    "    seed=42, final_forget=0.70, sched='linear', p_drop=0.5)\n",
    "\n",
    "tune_and_report_coteach_plus(\"datasets/CIFAR.npz\",\n",
    "    lr=1e-4, it_values=(300,), wd_values=(5e-2,),\n",
    "    seed=42, final_forget=0.75, sched='linear', p_drop=0.5)\n",
    "\n",
    "tune_and_report_coteach_plus(\"datasets/CIFAR.npz\",\n",
    "    lr=5e-4, it_values=(300,), wd_values=(5e-2,),\n",
    "    seed=42, final_forget=0.70, sched='linear', p_drop=0.5)\n",
    "\n",
    "tune_and_report_coteach_plus(\"datasets/CIFAR.npz\",\n",
    "    lr=5e-4, it_values=(300,), wd_values=(5e-2,),\n",
    "    seed=42, final_forget=0.75, sched='linear', p_drop=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e2f05c2-33ca-4a81-acc5-034091fb1462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Dataset: datasets/CIFAR.npz ====\n",
      "Tuned configs (both orientations):\n",
      "wd=0.05, it=300 | val_loss=0.6310, test_acc=50.00%\n",
      "** Best: wd=0.05, it=300 | val_loss=0.6310, test_acc=50.00%\n",
      "==== Dataset: datasets/CIFAR.npz ====\n",
      "Tuned configs (both orientations):\n",
      "wd=0.05, it=300 | val_loss=0.6357, test_acc=51.30%\n",
      "** Best: wd=0.05, it=300 | val_loss=0.6357, test_acc=51.30%\n",
      "==== Dataset: datasets/CIFAR.npz ====\n",
      "Tuned configs (both orientations):\n",
      "wd=0.05, it=300 | val_loss=0.6400, test_acc=52.83%\n",
      "** Best: wd=0.05, it=300 | val_loss=0.6400, test_acc=52.83%\n"
     ]
    }
   ],
   "source": [
    "# 固定 wd=0.05，线性调度、较高丢弃、更强 dropout\n",
    "tune_and_report_coteach_plus(\"datasets/CIFAR.npz\",\n",
    "    lr=1e-4, it_values=(300,), wd_values=(5e-2,),\n",
    "    seed=42, final_forget=0.70, sched='linear', p_drop=0.5)\n",
    "\n",
    "tune_and_report_coteach_plus(\"datasets/CIFAR.npz\",\n",
    "    lr=3e-4, it_values=(300,), wd_values=(5e-2,),\n",
    "    seed=42, final_forget=0.70, sched='linear', p_drop=0.5)\n",
    "\n",
    "tune_and_report_coteach_plus(\"datasets/CIFAR.npz\",\n",
    "    lr=5e-4, it_values=(300,), wd_values=(5e-2,),\n",
    "    seed=42, final_forget=0.70, sched='linear', p_drop=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ef5c71a-d4ad-4f45-aad7-ca5a076a9fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Dataset: datasets/CIFAR.npz ====\n",
      "Tuned configs (both orientations):\n",
      "wd=0.001, it=300 | val_loss=0.6480, test_acc=50.03%\n",
      "wd=0.0001, it=300 | val_loss=0.6433, test_acc=50.57%\n",
      "** Best: wd=0.0001, it=300 | val_loss=0.6433, test_acc=50.57%\n"
     ]
    }
   ],
   "source": [
    "# 扫 wd（300 epoch 先看趋势）\n",
    "tune_and_report_coteach_plus(\n",
    "    DATASET_3,\n",
    "    lr=3e-4,                      # 稳定起步\n",
    "    it_values=(300,),\n",
    "    wd_values=(1e-3,1e-4), # 强正则范围\n",
    "    seed=42,\n",
    "    final_forget=0.7,             # 比噪声率略高更激进\n",
    "    sched='linear',\n",
    "    p_drop=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebca55f9-c118-498e-8771-7d8a37d47fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Dataset: datasets/CIFAR.npz ====\n",
      "Tuned configs (both orientations):\n",
      "wd=0.01, it=300 | val_loss=0.6400, test_acc=52.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 扫 wd（300 epoch 先看趋势）\n",
    "tune_and_report_coteach_plus(\n",
    "    DATASET_3,\n",
    "    lr=3e-4,                      # 稳定起步\n",
    "    it_values=(300,),\n",
    "    wd_values=(1e-2, 5e-2, 1e-1), # 强正则范围\n",
    "    seed=42,\n",
    "    final_forget=0.7,             # 比噪声率略高更激进\n",
    "    sched='linear',\n",
    "    p_drop=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cf0acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.3 噪声——忘记率≈噪声率；正则弱一点，跑得更快\n",
    "tune_and_report_coteach_plus(\n",
    "    DATASET_1,\n",
    "    lr=1e-3,\n",
    "    it_values=(200,),\n",
    "    wd_values=(0.5,),      # 你已验证最佳\n",
    "    seed=42,\n",
    "    final_forget=0.3        # coteaching 旧版接口\n",
    ")\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "# 0.6 噪声——忘记率高、正则强一些\n",
    "tune_and_report_coteach_plus(\n",
    "    DATASET_2,\n",
    "    lr=3e-4,                          # 较稳\n",
    "    it_values=(300,),                 # 先 300 epoch 快扫\n",
    "    wd_values=(1e-2, 5e-2, 1e-1),     # 强正则范围\n",
    "    seed=42,\n",
    "    final_forget=0.7,                 # 比噪声率更激进一点\n",
    "    sched='linear',                   # 线性爬升更直接\n",
    "    p_drop=0.5                        # 更强 Dropout\n",
    "    # 如你在函数里有 warmup 参数，建议 warmup_epochs=12\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b5768e-4e9f-49d5-9a35-634fb0c6d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 组1：更激进丢样本 + 稍大WD\n",
    "tune_and_report_coteach_plus(DATASET_2, lr=3e-4, it_values=(300,),\n",
    "    wd_values=(5e-2, 1e-1), seed=42,\n",
    "    final_forget=0.70, sched='linear', p_drop=0.5)\n",
    "\n",
    "# 组2：final_forget 再高一点\n",
    "tune_and_report_coteach_plus(DATASET_2, lr=3e-4, it_values=(300,),\n",
    "    wd_values=(5e-2, 1e-1), seed=42,\n",
    "    final_forget=0.75, sched='linear', p_drop=0.5)\n",
    "\n",
    "# 组3：更小LR（配大WD更稳）\n",
    "tune_and_report_coteach_plus(DATASET_2, lr=1e-4, it_values=(300,),\n",
    "    wd_values=(1e-1, 2e-1), seed=42,\n",
    "    final_forget=0.70, sched='linear', p_drop=0.5)\n",
    "\n",
    "# 组4：同组3但 final_forget=0.75\n",
    "tune_and_report_coteach_plus(DATASET_2, lr=1e-4, it_values=(300,),\n",
    "    wd_values=(1e-1, 2e-1), seed=42,\n",
    "    final_forget=0.75, sched='linear', p_drop=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0a3afe-4434-4b48-8f9a-f22b01e619ea",
   "metadata": {},
   "source": [
    "# 最佳参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5830781b-1445-43d1-a794-3ccde8bdb0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_and_report_coteach_plus(\n",
    "    DATASET_1,\n",
    "    lr=1e-3,\n",
    "    it_values=(500,),\n",
    "    wd_values=(0.5,), \n",
    "    seed=42,\n",
    "    final_forget=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a201c75b-4725-47b7-96bd-b58b75aed0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_and_report_coteach_plus(\n",
    "    DATASET_2, \n",
    "    lr=1e-4, \n",
    "    it_values=(500,),\n",
    "    wd_values=(1e-1,), \n",
    "    seed=42,\n",
    "    final_forget=0.75, \n",
    "    sched='linear', \n",
    "    p_drop=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd7c10a-4303-4925-8ba6-8cb38f582d00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7678c661",
   "metadata": {},
   "source": [
    "## 一、导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "996c890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "import random\n",
    "import scipy.optimize as opt\n",
    "import scipy.linalg as sla\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309191eb",
   "metadata": {},
   "source": [
    "## 二、数据读取与处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd07528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载（复用作业给的风格）\n",
    "@dataclass\n",
    "class Dataset:\n",
    "    Xtr: np.ndarray  # noisy train+val 的特征\n",
    "    Str: np.ndarray  # noisy train+val 的标签（{0,1,2}）\n",
    "    Xts: np.ndarray  # clean test 的特征\n",
    "    Yts: np.ndarray  # clean test 的标签（{0,1,2}）\n",
    "\n",
    "def load_npz(path): \n",
    "    d=np.load(path); \n",
    "    return Dataset(d['Xtr'],d['Str'],d['Xts'],d['Yts'])\n",
    "\n",
    "#其他函数定义\n",
    "def set_seed(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "def one_hot(y: np.ndarray, C: int) -> np.ndarray:\n",
    "    oh = np.zeros((y.shape[0], C), dtype=np.float32)\n",
    "    oh[np.arange(y.shape[0]), y] = 1.0\n",
    "    return oh\n",
    "\n",
    "def softmax(z: np.ndarray) -> np.ndarray:\n",
    "    # 数值稳定\n",
    "    z = z - z.max(axis=1, keepdims=True)\n",
    "    expz = np.exp(z)\n",
    "    return expz / (expz.sum(axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "def accuracy(y, yhat): return float((y==yhat).mean())\n",
    "\n",
    "\n",
    "#根据文件名返回已知的转移矩阵 T。\n",
    "def get_T(name: str) -> np.ndarray:\n",
    "    name = name.lower()\n",
    "    if \"0.3\" in name:\n",
    "        T = np.array([[0.7, 0.3, 0.0],\n",
    "                      [0.0, 0.7, 0.3],\n",
    "                      [0.3, 0.0, 0.7]], dtype=np.float32)\n",
    "    elif \"0.6\" in name:\n",
    "        T = np.array([[0.4, 0.3, 0.3],\n",
    "                      [0.3, 0.4, 0.3],\n",
    "                      [0.3, 0.3, 0.4]], dtype=np.float32)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown dataset: only 0.3 and 0.6 are supported here.\")\n",
    "    return T\n",
    "\n",
    "# 训练集划分\n",
    "def split(X,y,ratio=0.2,seed=42):\n",
    "    set_seed(seed); \n",
    "    n=X.shape[0]; \n",
    "    idx=np.random.permutation(n); \n",
    "    sp=int(n*(1-ratio))\n",
    "    return X[idx[:sp]],y[idx[:sp]],X[idx[sp:]],y[idx[sp:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2611ddf3",
   "metadata": {},
   "source": [
    "## 三、ccn算法实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec29a327",
   "metadata": {},
   "source": [
    "### prepocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ecb9e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Standardizer:\n",
    "    mean: np.ndarray; std: np.ndarray\n",
    "    def transform(self,Xf):\n",
    "        Xn=(Xf-self.mean)/self.std\n",
    "        bias=np.ones((Xn.shape[0],1),dtype=np.float64)\n",
    "        return np.hstack([Xn,bias])\n",
    "\n",
    "def flatten(X): \n",
    "    return X.reshape(X.shape[0],-1).astype(np.float64)\n",
    "def fit_std(Xtrf): \n",
    "    m=Xtrf.mean(0,keepdims=True); \n",
    "    s=Xtrf.std(0,keepdims=True)+1e-5; \n",
    "    return Standardizer(m,s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62631634",
   "metadata": {},
   "source": [
    "### forward方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33141501",
   "metadata": {},
   "source": [
    "Forward 方法：把「干净预测分布」p_clean 乘以 T^T，得到 noisy 标签的预测分布：p_tilde = T^T * p_clean，然后对 noisy 标签做交叉熵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a27e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_loss(p_clean, y, T):\n",
    "    p_tilde = p_clean @ T         \n",
    "    p_tilde = np.clip(p_tilde, 1e-12, 1.0)\n",
    "    return float(-np.log(p_tilde[np.arange(y.shape[0]), y]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225290ef",
   "metadata": {},
   "source": [
    "返回 dL/dz（对logits的梯度）。便于与线性层合成 dL/dW = X^T @ dL/dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e061503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dLdz_forward(p_clean, y, T):\n",
    "    N, C = p_clean.shape\n",
    "    Y = one_hot(y, C)\n",
    "    p_tilde = p_clean @ T\n",
    "    p_tilde = np.clip(p_tilde, 1e-12, 1.0)\n",
    "    dL_dp_tilde = -(Y / p_tilde) / N\n",
    "    dL_dp_clean = dL_dp_tilde @ T.T\n",
    "    s = (dL_dp_clean * p_clean).sum(axis=1, keepdims=True)\n",
    "    dL_dz = p_clean * (dL_dp_clean - s)\n",
    "    return dL_dz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b148e9",
   "metadata": {},
   "source": [
    "### 多类逻辑回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bee93966",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FwdCfg: wd:float=1e-4; max_iter:int=300; seed:int=42\n",
    "class SoftmaxFwd:\n",
    "    def __init__(self, D, C, T, cfg:FwdCfg):\n",
    "        self.D, self.C, self.T, self.cfg = D, C, T, cfg\n",
    "        set_seed(cfg.seed)\n",
    "        self.W = (0.01*np.random.randn(D,C)).astype(np.float64)\n",
    "    def _fun(self,w,X,y):\n",
    "        W=w.reshape(self.D,self.C); p=softmax(X@W)\n",
    "        base=forward_loss(p,y,self.T)\n",
    "        reg =0.5*self.cfg.wd*(sla.norm(W,'fro')**2)\n",
    "        dLdz=dLdz_forward(p,y,self.T)\n",
    "        grad = X.T@dLdz + self.cfg.wd*W\n",
    "        return base+reg, grad.reshape(-1)\n",
    "    def fit(self,X,y):\n",
    "        res=opt.minimize(self._fun,self.W.reshape(-1),args=(X,y),method=\"L-BFGS-B\",jac=True,\n",
    "                         options={\"maxiter\":self.cfg.max_iter})  # 不再传 disp，避免 warning\n",
    "        self.W=res.x.reshape(self.D,self.C); return res\n",
    "    def predict_proba(self,X): return softmax(X@self.W)\n",
    "    def predict(self,X): return self.predict_proba(X).argmax(1)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146ef5ab",
   "metadata": {},
   "source": [
    "### 调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a47c3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Result:\n",
    "    cfg: \"FwdCfg\"\n",
    "    val_loss: float\n",
    "    test_acc: float\n",
    "\n",
    "#10折交叉验证\n",
    "def search_with_direction_cv(Xtr, Str, Xts, Yts, T, seed=42, n_splits=10) -> Tuple[Result, List[Result]]:\n",
    "    # 展平\n",
    "    Xtr_f = flatten(Xtr)\n",
    "    Xts_f = flatten(Xts)\n",
    "    C = T.shape[0]\n",
    "    D = Xtr_f.shape[1]\n",
    "\n",
    "    # 超参网格（可按需改）\n",
    "    grid = [\n",
    "        FwdCfg(wd=1e-4, max_iter=500, seed=seed),\n",
    "        FwdCfg(wd=1e-3, max_iter=500, seed=seed),\n",
    "        FwdCfg(wd=1e-2, max_iter=500, seed=seed),\n",
    "        FwdCfg(wd=5e-2, max_iter=500, seed=seed),\n",
    "        FwdCfg(wd=1e-1, max_iter=500, seed=seed),\n",
    "        FwdCfg(wd=5e-1, max_iter=500, seed=seed),\n",
    "    ]\n",
    "\n",
    "    # 分层 10 折（对噪声标签 Str 分层即可）\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    cfg_cv_losses = []   # [(cfg, mean_val_loss)]\n",
    "    for cfg in grid:\n",
    "        fold_losses = []\n",
    "        for tr_idx, val_idx in skf.split(Xtr_f, Str):\n",
    "            X_tr_raw, y_tr = Xtr_f[tr_idx], Str[tr_idx]\n",
    "            X_val_raw, y_val = Xtr_f[val_idx], Str[val_idx]\n",
    "\n",
    "            # 只用本折训练部分拟合标准化器，避免泄露\n",
    "            std = fit_std(X_tr_raw)\n",
    "            X_tr = std.transform(X_tr_raw)\n",
    "            X_val = std.transform(X_val_raw)\n",
    "\n",
    "            # 训练并在该折验证\n",
    "            model = SoftmaxFwd(D, C, T, cfg)\n",
    "            model.fit(X_tr, y_tr)\n",
    "\n",
    "            p_val = model.predict_proba(X_val)\n",
    "            vloss = forward_loss(p_val, y_val, T) + 0.5 * cfg.wd * (sla.norm(model.W, 'fro') ** 2)\n",
    "            fold_losses.append(vloss)\n",
    "\n",
    "        cfg_cv_losses.append((cfg, float(np.mean(fold_losses))))\n",
    "\n",
    "    # 选平均验证损失最小的 cfg\n",
    "    best_cfg, best_cv_loss = min(cfg_cv_losses, key=lambda x: x[1])\n",
    "\n",
    "    std_full = fit_std(Xtr_f)\n",
    "    X_tr_full = std_full.transform(Xtr_f)\n",
    "    X_te = std_full.transform(Xts_f)\n",
    "\n",
    "    best_model = SoftmaxFwd(D, C, T, best_cfg)\n",
    "    best_model.fit(X_tr_full, Str)\n",
    "\n",
    "    test_acc = accuracy(Yts, best_model.predict(X_te))\n",
    "\n",
    "    results: List[Result] = [\n",
    "        Result(cfg=cfg, val_loss=mean_vloss, test_acc=test_acc if cfg is best_cfg else np.nan)\n",
    "        for cfg, mean_vloss in cfg_cv_losses\n",
    "    ]\n",
    "\n",
    "    best = Result(cfg=best_cfg, val_loss=best_cv_loss, test_acc=test_acc)\n",
    "    return best, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4739b0cb",
   "metadata": {},
   "source": [
    "## 四、main部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58519e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Dataset: datasets/FashionMNIST0.3.npz ====\n",
      "Tuned configs (both orientations):\n",
      "  [p@T] wd=0.0001, it=500 | val_loss=0.7299, test_acc=95.47%\n",
      "  [p@T] wd=0.001, it=500 | val_loss=0.6817, test_acc=96.23%\n",
      "  [p@T] wd=0.05, it=500 | val_loss=0.6749, test_acc=97.07%\n",
      "  [p@T] wd=0.01, it=500 | val_loss=0.6633, test_acc=97.47%\n",
      "  [p@T] wd=0.5, it=500 | val_loss=0.7295, test_acc=96.30%\n",
      "  [p@T] wd=0.1, it=500 | val_loss=0.6854, test_acc=96.93%\n",
      "** Best: [p@T] wd=0.01, it=500 | val_loss=0.6633, test_acc=97.47%\n",
      "\n",
      "==== Dataset: datasets/FashionMNIST0.6.npz ====\n",
      "Tuned configs (both orientations):\n",
      "  [p@T] wd=0.0001, it=500 | val_loss=1.1009, test_acc=72.17%\n",
      "  [p@T] wd=0.001, it=500 | val_loss=1.0996, test_acc=72.77%\n",
      "  [p@T] wd=0.05, it=500 | val_loss=1.0935, test_acc=95.13%\n",
      "  [p@T] wd=0.01, it=500 | val_loss=1.0943, test_acc=92.10%\n",
      "  [p@T] wd=0.5, it=500 | val_loss=1.0964, test_acc=92.83%\n",
      "  [p@T] wd=0.1, it=500 | val_loss=1.0941, test_acc=94.97%\n",
      "** Best: [p@T] wd=0.05, it=500 | val_loss=1.0935, test_acc=95.13%\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    set_seed(42)\n",
    "    datasets = [\n",
    "        \"datasets/FashionMNIST0.3.npz\",\n",
    "        \"datasets/FashionMNIST0.6.npz\",\n",
    "    ]\n",
    "    for path in datasets:\n",
    "        print(f\"\\n==== Dataset: {path} ====\")\n",
    "        T = get_T(path)\n",
    "        data = load_npz(path)\n",
    "        best, results = search_with_direction(data.Xtr, data.Str, data.Xts, data.Yts, T, seed=42)\n",
    "\n",
    "        def fmt(r:Result):\n",
    "            return f\"[p@T] wd={r.cfg.wd}, it={r.cfg.max_iter} | val_loss={r.val_loss:.4f}, test_acc={r.test_acc*100:.2f}%\"\n",
    "\n",
    "        print(\"Tuned configs (both orientations):\")\n",
    "        for r in results: print(\" \", fmt(r))\n",
    "        print(\"** Best:\", fmt(best))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c099118",
   "metadata": {},
   "source": [
    "### 以下是用最佳wd以及东晴提供的转移矩阵来跑CIFAR数据集的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beda0685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Dataset: datasets/CIFAR.npz ====\n",
      "Tuned configs with 10-fold CV (forward loss):\n",
      "  [p@T] wd=0.0001, it=500 | mean_val_loss=1.1006 (±0.0027)\n",
      "  [p@T] wd=0.001, it=500 | mean_val_loss=1.1042 (±0.0019)\n",
      "  [p@T] wd=0.05, it=500 | mean_val_loss=1.0962 (±0.0015)\n",
      "  [p@T] wd=0.01, it=500 | mean_val_loss=1.0985 (±0.0018)\n",
      "  [p@T] wd=0.5, it=500 | mean_val_loss=1.0966 (±0.0011)\n",
      "  [p@T] wd=0.1, it=500 | mean_val_loss=1.0961 (±0.0014)\n",
      "  [p@T] wd=0.2, it=500 | mean_val_loss=1.0962 (±0.0013)\n",
      "  [p@T] wd=0.5, it=500 | mean_val_loss=1.0966 (±0.0011)\n",
      "** Best (by 10-fold mean val loss): [p@T] wd=0.1, it=500 | mean_val_loss=1.0961 (±0.0014), test_acc=66.67%\n"
     ]
    }
   ],
   "source": [
    "# ==== CIFAR (ForwardCorrection, softmax) - 10-fold CV on wd (fixed dims) ====\n",
    "\n",
    "# 已给的 T 与数据路径\n",
    "T_CIFAR = np.array([[0.3983,0.332 ,0.2697],\n",
    "                    [0.2967,0.3587,0.3447],\n",
    "                    [0.31  ,0.3097,0.3803]], dtype=np.float64)\n",
    "DATASET_PATH = \"datasets/CIFAR.npz\"\n",
    "\n",
    "# 载入\n",
    "d = np.load(DATASET_PATH)\n",
    "Xtr, Str, Xts, Yts = d['Xtr'], d['Str'], d['Xts'], d['Yts']\n",
    "\n",
    "# 展平（不要先做固定切分）\n",
    "Xtr_f = flatten(Xtr)\n",
    "Xts_f = flatten(Xts)\n",
    "\n",
    "@dataclass\n",
    "class FwdCfg:\n",
    "    wd: float = 0.05\n",
    "    max_iter: int = 500\n",
    "    seed: int = 42\n",
    "\n",
    "C = T_CIFAR.shape[0]\n",
    "seed = 42\n",
    "\n",
    "# 待测试的 wd 列表（沿用你原来的顺序）\n",
    "grid = [\n",
    "    FwdCfg(wd=1e-4, max_iter=500, seed=seed),\n",
    "    FwdCfg(wd=1e-3, max_iter=500, seed=seed),\n",
    "    FwdCfg(wd=5e-2, max_iter=500, seed=seed),\n",
    "    FwdCfg(wd=1e-2, max_iter=500, seed=seed),\n",
    "    FwdCfg(wd=5e-1, max_iter=500, seed=seed),\n",
    "    FwdCfg(wd=1e-1, max_iter=500, seed=seed),\n",
    "    FwdCfg(wd=0.2,   max_iter=500, seed=seed),\n",
    "    FwdCfg(wd=0.5,   max_iter=500, seed=seed),\n",
    "]\n",
    "\n",
    "print(f\"\\n==== Dataset: {DATASET_PATH} ====\")\n",
    "print(\"Tuned configs with 10-fold CV (forward loss):\")\n",
    "\n",
    "# 10 折分层（按噪声标签 Str 分层）\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "# 逐 cfg 做交叉验证\n",
    "cv_summaries = []  # [(cfg, mean_vloss, std_vloss)]\n",
    "for cfg in grid:\n",
    "    fold_losses = []\n",
    "    for tr_idx, val_idx in skf.split(Xtr_f, Str):\n",
    "        # 划分本折数据\n",
    "        X_tr_raw, y_tr = Xtr_f[tr_idx], Str[tr_idx]\n",
    "        X_val_raw, y_val = Xtr_f[val_idx], Str[val_idx]\n",
    "\n",
    "        std = fit_std(X_tr_raw)\n",
    "        X_tr = std.transform(X_tr_raw)\n",
    "        X_val = std.transform(X_val_raw)\n",
    "\n",
    "        D_fold = X_tr.shape[1]\n",
    "\n",
    "        # 训练并在该折验证\n",
    "        model = SoftmaxFwd(D_fold, C, T_CIFAR, cfg)\n",
    "        res = model.fit(X_tr, y_tr)\n",
    "\n",
    "        p_val = model.predict_proba(X_val)\n",
    "        vloss = forward_loss(p_val, y_val, T_CIFAR) + 0.5 * cfg.wd * (sla.norm(model.W, 'fro')**2)\n",
    "        fold_losses.append(float(vloss))\n",
    "\n",
    "    mean_vloss = float(np.mean(fold_losses))\n",
    "    std_vloss  = float(np.std(fold_losses, ddof=1)) if len(fold_losses) > 1 else 0.0\n",
    "    cv_summaries.append((cfg, mean_vloss, std_vloss))\n",
    "    print(f\"  [p@T] wd={cfg.wd:g}, it={cfg.max_iter} | mean_val_loss={mean_vloss:.4f} (±{std_vloss:.4f})\")\n",
    "\n",
    "# 选平均验证损失最小的 cfg\n",
    "best_cfg, best_mean_vloss, best_std = min(cv_summaries, key=lambda x: x[1])\n",
    "\n",
    "std_full = fit_std(Xtr_f)\n",
    "X_tr_full = std_full.transform(Xtr_f)\n",
    "X_te      = std_full.transform(Xts_f)\n",
    "\n",
    "D_full = X_tr_full.shape[1]\n",
    "best_model = SoftmaxFwd(D_full, C, T_CIFAR, best_cfg)\n",
    "res_full = best_model.fit(X_tr_full, Str)\n",
    "\n",
    "# 测试集准确率（clean）\n",
    "test_acc = float((best_model.predict(X_te) == Yts).mean())\n",
    "\n",
    "# 汇总 results\n",
    "results = []\n",
    "for cfg, mean_vloss, std_vloss in cv_summaries:\n",
    "    results.append({\n",
    "        \"wd\": cfg.wd,\n",
    "        \"iters\": getattr(res_full, \"nit\", \"N/A\") if cfg is best_cfg else \"N/A\",\n",
    "        \"val_loss\": mean_vloss,         # 10 折平均验证损失\n",
    "        \"val_loss_std\": std_vloss,      # 波动\n",
    "        \"test_acc\": test_acc if cfg is best_cfg else float('nan'),\n",
    "    })\n",
    "\n",
    "# 打印最优\n",
    "print(f\"** Best (by 10-fold mean val loss): [p@T] wd={best_cfg.wd:g}, it={best_cfg.max_iter} | \"\n",
    "      f\"mean_val_loss={best_mean_vloss:.4f} (±{best_std:.4f}), test_acc={test_acc*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

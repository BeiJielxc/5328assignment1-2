{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4140ef1c",
   "metadata": {},
   "source": [
    "# Co-Teaching++ (GPU, Forget-Rate Schedule + Dropout/BN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f83eff-a756-4936-849b-349f336f03ba",
   "metadata": {},
   "source": [
    "# 1.导入库并使用GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f54ebb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "# ==== Deterministic setup (reproducibility) ====\n",
    "import os, random, numpy as np, torch, math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PIN_MEMORY = bool(torch.cuda.is_available())\n",
    "NUM_WORKERS = 0  # keep 0 to avoid multi-process RNG issues unless necessary\n",
    "\n",
    "# Make cuDNN deterministic globally\n",
    "try:\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "except Exception as _e:\n",
    "    pass\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    try:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    except Exception as _e:\n",
    "        pass\n",
    "print(\"Device:\", DEVICE)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d5a4f0-23cf-4d34-aebe-03e9aeeb335f",
   "metadata": {},
   "source": [
    "# 2.数据加载与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1c4999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    import os, random, numpy as np, torch\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def _infer_hw_c_from_flat_dim(D:int):\n",
    "    s = int(np.sqrt(D) + 1e-8)\n",
    "    if s*s == D: return s, s, 1\n",
    "    if D % 3 == 0:\n",
    "        s3 = int(np.sqrt(D//3) + 1e-8)\n",
    "        if s3*s3*3 == D: return s3, s3, 3\n",
    "    return None, None, None\n",
    "\n",
    "def load_npz(path:str):\n",
    "    d = np.load(path)\n",
    "    Xtr, Str = d[\"Xtr\"], d[\"Str\"]\n",
    "    Xts, Yts = d[\"Xts\"], d[\"Yts\"]\n",
    "    if Xtr.ndim == 4 and Xtr.shape[-1]==3: H,W,C = Xtr.shape[1], Xtr.shape[2], 3\n",
    "    elif Xtr.ndim == 3: H,W,C = Xtr.shape[1], Xtr.shape[2], 1\n",
    "    elif Xtr.ndim == 2:\n",
    "        H,W,C = _infer_hw_c_from_flat_dim(Xtr.shape[1])\n",
    "        if H is None: raise ValueError(\"Cannot infer HWC\")\n",
    "    else: raise ValueError(f\"Bad shape: {Xtr.shape}\")\n",
    "    num_classes = int(max(Str.max(), Yts.max())+1)\n",
    "    return (Xtr, Str, Xts, Yts, (H,W,C), num_classes)\n",
    "\n",
    "class NPZImageDataset(Dataset):\n",
    "    def __init__(self, X, y, shape_hw_c):\n",
    "        X = X.astype(np.float32)\n",
    "        H,W,C = shape_hw_c\n",
    "        if X.ndim == 2:\n",
    "            X = X.reshape(-1,H,W) if C==1 else X.reshape(-1,H,W,C)\n",
    "        if X.max()>1.5: X = X/255.0\n",
    "        if X.ndim == 3: X = X[:,None,:,:]\n",
    "        elif X.ndim == 4: X = np.transpose(X,(0,3,1,2))\n",
    "        X = (X - X.mean())/(X.std()+1e-6)\n",
    "        self.X, self.y = X, y.astype(np.int64)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self,i): return torch.from_numpy(self.X[i]), int(self.y[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a613d9-e21d-4ba4-8412-d1a2c4165293",
   "metadata": {},
   "source": [
    "# 3.定义卷积神经网络 CNN 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "939d3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_BN_Drop(nn.Module):\n",
    "    def __init__(self, in_ch=1, num_classes=10, p_drop=0.4):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(p_drop),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(p_drop),\n",
    "        )\n",
    "        self.adapt = nn.AdaptiveAvgPool2d((7,7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*7*7, 256), nn.ReLU(),\n",
    "            nn.Dropout(p_drop),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = self.adapt(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "def make_model(in_ch, C, p_drop=0.4):\n",
    "    return CNN_BN_Drop(in_ch=in_ch, num_classes=C, p_drop=p_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7646eeee-7918-41b4-93bc-8f26f5e750df",
   "metadata": {},
   "source": [
    "# 4.算法训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b91a513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_indices_by_small_loss(logits, y, keep_ratio):\n",
    "    losses = F.cross_entropy(logits, y, reduction='none')\n",
    "    k = max(1, int(keep_ratio * len(losses)))\n",
    "    return torch.topk(-losses, k=k).indices\n",
    "\n",
    "def coteach_epoch(model1, model2, loader, opt1, opt2, keep_ratio):\n",
    "    model1.train(); model2.train(); total=0.0\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "        l1, l2 = model1(x), model2(x)\n",
    "        idx1 = topk_indices_by_small_loss(l1, y, keep_ratio)\n",
    "        idx2 = topk_indices_by_small_loss(l2, y, keep_ratio)\n",
    "        loss1 = F.cross_entropy(l1[idx2], y[idx2])\n",
    "        loss2 = F.cross_entropy(l2[idx1], y[idx1])\n",
    "        opt1.zero_grad(); loss1.backward(); opt1.step()\n",
    "        opt2.zero_grad(); loss2.backward(); opt2.step()\n",
    "        total += (loss1.item()+loss2.item())/2\n",
    "    return total/len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval(); corr=0; tot=0\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "        pred = model(x).argmax(1)\n",
    "        corr += (pred==y).sum().item(); tot += y.size(0)\n",
    "    return corr/tot\n",
    "\n",
    "def linear_schedule(epoch, max_epoch, final_forget):\n",
    "    return min(final_forget, final_forget * epoch / max(1, max_epoch))\n",
    "\n",
    "def cosine_schedule(epoch, max_epoch, final_forget):\n",
    "    t = epoch / max(1, max_epoch)\n",
    "    return final_forget * (0.5 - 0.5*math.cos(math.pi * t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9990600-737f-47ab-ba47-7482813e644c",
   "metadata": {},
   "source": [
    "# 5.训练配置：Co-teaching的单独训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0567310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_config_coteach_scheduled(\n",
    "    dataset_path, epochs, wd, lr, seed=2025,\n",
    "    final_forget=0.6, sched='linear', p_drop=0.4,\n",
    "    warmup_epochs=8,\n",
    "    tr_idx=None, va_idx=None,\n",
    "    generator=None\n",
    "):\n",
    "    # 固定所有随机性\n",
    "    set_seed(seed)\n",
    "\n",
    "    # 加载数据\n",
    "    Xtr, Str, Xts, Yts, hwc, C = load_npz(dataset_path)\n",
    "\n",
    "    # 若外部未传入折索引，则使用固定8:2划分\n",
    "    if tr_idx is None or va_idx is None:\n",
    "        tr_idx, va_idx = train_test_split(\n",
    "            np.arange(len(Str)), test_size=0.2, stratify=Str, random_state=seed\n",
    "        )\n",
    "\n",
    "    # 构建数据集\n",
    "    tr = NPZImageDataset(Xtr[tr_idx], Str[tr_idx], shape_hw_c=hwc)\n",
    "    va = NPZImageDataset(Xtr[va_idx], Str[va_idx], shape_hw_c=hwc)\n",
    "    ts = NPZImageDataset(Xts, Yts, shape_hw_c=hwc)\n",
    "\n",
    "    # DataLoader（训练集传入 generator 锁定 shuffle）\n",
    "    tr_loader = DataLoader(tr, batch_size=256, shuffle=True,\n",
    "                           num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
    "                           generator=generator)\n",
    "    va_loader = DataLoader(va, batch_size=256, shuffle=False,\n",
    "                           num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "    ts_loader = DataLoader(ts, batch_size=256, shuffle=False,\n",
    "                           num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "    # 初始化模型和优化器\n",
    "    in_ch = hwc[2]\n",
    "    m1 = make_model(in_ch, C, p_drop).to(DEVICE)\n",
    "    m2 = make_model(in_ch, C, p_drop).to(DEVICE)\n",
    "    opt1 = torch.optim.AdamW(m1.parameters(), lr=lr, weight_decay=wd)\n",
    "    opt2 = torch.optim.AdamW(m2.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    # ======= 训练 =======\n",
    "    for ep in range(1, epochs + 1):\n",
    "        if ep <= warmup_epochs:\n",
    "            m1.train(); m2.train()\n",
    "            for x, y in tr_loader:\n",
    "                x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "                opt1.zero_grad(set_to_none=True)\n",
    "                F.cross_entropy(m1(x), y).backward()\n",
    "                opt1.step()\n",
    "                opt2.zero_grad(set_to_none=True)\n",
    "                F.cross_entropy(m2(x), y).backward()\n",
    "                opt2.step()\n",
    "            continue\n",
    "\n",
    "        # Warmup 结束后进入 Co-Teaching\n",
    "        t_ep = ep - warmup_epochs\n",
    "        T_total = max(1, epochs - warmup_epochs)\n",
    "        if sched == 'cosine':\n",
    "            forget = cosine_schedule(t_ep, T_total, final_forget)\n",
    "        else:\n",
    "            forget = linear_schedule(t_ep, T_total, final_forget)\n",
    "\n",
    "        keep_ratio = float(min(1.0, max(0.0, 1.0 - forget)))\n",
    "        coteach_epoch(m1, m2, tr_loader, opt1, opt2, keep_ratio)\n",
    "\n",
    "    # ======= 评估 =======\n",
    "    va_acc = max(evaluate(m1, va_loader), evaluate(m2, va_loader))\n",
    "    ts_acc = max(evaluate(m1, ts_loader), evaluate(m2, ts_loader))\n",
    "    val_loss = 1.0 - va_acc\n",
    "    return val_loss, ts_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba743aeb-ca27-48aa-9dbe-c4cf92f85233",
   "metadata": {},
   "source": [
    "# Co-teaching的十折训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03837937-c2a9-4b0c-83d6-68ad694b672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def tune_and_report_coteach_plus_cv(\n",
    "    dataset_path,\n",
    "    lr=1e-3,\n",
    "    it_values=(30,),\n",
    "    wd_values=(5e-2,),\n",
    "    seed=42,\n",
    "    final_forget=0.6,\n",
    "    sched='linear',\n",
    "    p_drop=0.5,\n",
    "    num_folds=10\n",
    "):\n",
    "    print(f\"==== 10-Fold CV on Dataset: {dataset_path} ====\")\n",
    "\n",
    "    # 固定主随机种子\n",
    "    set_seed(seed)\n",
    "\n",
    "    # 一次性加载数据\n",
    "    Xtr, Str, Xts, Yts, hwc, C = load_npz(dataset_path)\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    fold_accs, fold_losses = [], []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(Xtr)):\n",
    "        print(f\"\\n===== Fold {fold + 1}/{num_folds} =====\")\n",
    "        # 每折单独 generator，确保 shuffle 顺序一致\n",
    "        g = torch.Generator(device='cpu').manual_seed(seed + fold)\n",
    "\n",
    "        best = None\n",
    "        for it in it_values:\n",
    "            for wd in wd_values:\n",
    "                vloss, tacc = train_config_coteach_scheduled(\n",
    "                    dataset_path=dataset_path,\n",
    "                    epochs=it, wd=wd, lr=lr,\n",
    "                    seed=seed + fold,              # 每折固定种子\n",
    "                    final_forget=final_forget,\n",
    "                    sched=sched,\n",
    "                    p_drop=p_drop,\n",
    "                    tr_idx=train_idx, va_idx=val_idx,\n",
    "                    generator=g\n",
    "                )\n",
    "                print(f\"Fold {fold+1} | wd={wd}, it={it} | val_loss={vloss:.4f}, test_acc={tacc*100:.2f}%\")\n",
    "\n",
    "                if (best is None) or (vloss < best[0] - 1e-12) or (abs(vloss - best[0]) < 1e-12 and tacc > best[1]):\n",
    "                    best = (vloss, tacc, wd, it)\n",
    "\n",
    "        fold_losses.append(best[0])\n",
    "        fold_accs.append(best[1])\n",
    "\n",
    "    mean_acc = float(np.mean(fold_accs))\n",
    "    std_acc  = float(np.std(fold_accs))\n",
    "    mean_loss = float(np.mean(fold_losses))\n",
    "\n",
    "    print(\"\\n==== 10-Fold Cross Validation Result ====\")\n",
    "    print(f\"Mean Val Loss: {mean_loss:.4f}\")\n",
    "    print(f\"Mean Test Accuracy: {mean_acc*100:.2f}% ± {std_acc*100:.2f}%\")\n",
    "    return mean_loss, mean_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a1f206-04cb-44a5-9140-47015554fd8f",
   "metadata": {},
   "source": [
    "# 6.网格调参 + 报告最佳结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d640fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_report_coteach_plus(\n",
    "    dataset_path,\n",
    "    lr=1e-3,\n",
    "    it_values=(500,),\n",
    "    wd_values=(1e-4, 1e-3, 5e-2, 1e-2, 5e-1, 1e-1),\n",
    "    seed=42,\n",
    "    final_forget=0.6,\n",
    "    sched='linear',\n",
    "    p_drop=0.4,\n",
    "    return_best=False\n",
    "):\n",
    "    print(f\"==== Dataset: {dataset_path} ====\")\n",
    "    print(\"Tuned configs (both orientations):\")\n",
    "    best = None\n",
    "    set_seed(seed)\n",
    "\n",
    "    for it in it_values:\n",
    "        for wd in wd_values:\n",
    "            g = torch.Generator(device='cpu').manual_seed(seed)\n",
    "            vloss, tacc = train_config_coteach_scheduled(\n",
    "                dataset_path=dataset_path,\n",
    "                epochs=it,\n",
    "                wd=wd,\n",
    "                lr=lr,\n",
    "                seed=seed,\n",
    "                final_forget=final_forget,\n",
    "                sched=sched,\n",
    "                p_drop=p_drop,\n",
    "                generator=g\n",
    "            )\n",
    "            print(f\"wd={wd}, it={it} | val_loss={vloss:.4f}, test_acc={tacc*100:.2f}%\")\n",
    "            if (best is None) or (tacc > best[1] + 1e-12) or (abs(tacc - best[1]) < 1e-12 and vloss < best[0]):\n",
    "                best = (vloss, tacc, wd, it)\n",
    "    print(f\"** Best: wd={best[2]}, it={best[3]} | test_acc={best[1]*100:.2f}%, val_loss={best[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "803f2398-a035-4890-b8dd-e0717196ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定你的数据集路径\n",
    "DATASET_1 = \"datasets/FashionMNIST0.3.npz\"\n",
    "DATASET_2 = \"datasets/FashionMNIST0.6.npz\"\n",
    "DATASET_3 = \"datasets/CIFAR.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca1dad-d85c-4bd9-8f64-932c076ccb74",
   "metadata": {},
   "source": [
    "# 调参过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa1520e5-ae3f-4669-9a91-c7855d766d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Dataset: datasets/FashionMNIST0.3.npz ====\n",
      "Tuned configs (both orientations):\n",
      "wd=0.05, it=10 | val_loss=0.3164, test_acc=98.60%\n",
      "wd=0.01, it=10 | val_loss=0.3158, test_acc=98.57%\n",
      "wd=0.5, it=10 | val_loss=0.3153, test_acc=98.30%\n",
      "wd=0.1, it=10 | val_loss=0.3150, test_acc=98.63%\n",
      "** Best: wd=0.1, it=10 | test_acc=98.63%, val_loss=0.3150\n"
     ]
    }
   ],
   "source": [
    "tune_and_report_coteach_plus(\n",
    "    DATASET_1, \n",
    "    lr=1e-3, \n",
    "    it_values=(10,),\n",
    "    wd_values=(5e-2,1e-2,5e-1,1e-1), \n",
    "    seed=42,\n",
    "    final_forget=0.3, \n",
    "    sched='linear', \n",
    "    p_drop=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a201c75b-4725-47b7-96bd-b58b75aed0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Dataset: datasets/FashionMNIST0.6.npz ====\n",
      "Tuned configs (both orientations):\n",
      "wd=0.0001, it=30 | val_loss=0.6228, test_acc=97.13%\n",
      "wd=0.5, it=30 | val_loss=0.6217, test_acc=97.13%\n",
      "wd=0.1, it=30 | val_loss=0.6206, test_acc=96.53%\n",
      "** Best: wd=0.5, it=30 | test_acc=97.13%, val_loss=0.6217\n"
     ]
    }
   ],
   "source": [
    "tune_and_report_coteach_plus(\n",
    "    DATASET_2, \n",
    "    lr=1e-4, \n",
    "    it_values=(30,),\n",
    "    wd_values=(1e-4,5e-1,1e-1,), \n",
    "    seed=42,\n",
    "    final_forget=0.75, \n",
    "    sched='linear', \n",
    "    p_drop=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbd7c10a-4303-4925-8ba6-8cb38f582d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Dataset: datasets/CIFAR.npz ====\n",
      "Tuned configs (both orientations):\n",
      "wd=0.05, it=10 | val_loss=0.6520, test_acc=41.73%\n",
      "wd=0.0001, it=10 | val_loss=0.6530, test_acc=37.07%\n",
      "wd=0.5, it=10 | val_loss=0.6390, test_acc=51.37%\n",
      "wd=0.1, it=10 | val_loss=0.6667, test_acc=33.33%\n",
      "** Best: wd=0.5, it=10 | test_acc=51.37%, val_loss=0.6390\n"
     ]
    }
   ],
   "source": [
    "tune_and_report_coteach_plus(\n",
    "    DATASET_3,\n",
    "    lr=1e-4, \n",
    "    it_values=(10,), \n",
    "    wd_values=(5e-2,1e-4,5e-1,1e-1),\n",
    "    seed=42, \n",
    "    final_forget=0.74,\n",
    "    sched='linear', \n",
    "    p_drop=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7056310-2785-4f96-bf19-8c13de8b39a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Dataset: datasets/CIFAR.npz ====\n",
      "Tuned configs (both orientations):\n",
      "wd=0.5, it=10 | val_loss=0.6453, test_acc=34.50%\n",
      "wd=0.5, it=20 | val_loss=0.6250, test_acc=53.33%\n",
      "wd=0.5, it=30 | val_loss=0.6130, test_acc=72.47%\n",
      "** Best: wd=0.5, it=30 | test_acc=72.47%, val_loss=0.6130\n"
     ]
    }
   ],
   "source": [
    "tune_and_report_coteach_plus(\n",
    "    DATASET_3,\n",
    "    lr=1e-4, \n",
    "    it_values=(10,20,30), \n",
    "    wd_values=(5e-1,),\n",
    "    seed=42, \n",
    "    final_forget=0.74,\n",
    "    sched='linear', \n",
    "    p_drop=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0a3afe-4434-4b48-8f9a-f22b01e619ea",
   "metadata": {},
   "source": [
    "# 最佳参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "046f5f6d-c931-4c96-8b72-007f31042c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== 10-Fold CV on Dataset: datasets/FashionMNIST0.3.npz ====\n",
      "\n",
      "===== Fold 1/10 =====\n",
      "Fold 1 | wd=0.1, it=10 | val_loss=0.3039, test_acc=98.63%\n",
      "** Best in Fold 1: wd=0.1, it=10 | val_loss=0.3039, test_acc=98.63%\n",
      "\n",
      "===== Fold 2/10 =====\n",
      "Fold 2 | wd=0.1, it=10 | val_loss=0.2972, test_acc=98.60%\n",
      "** Best in Fold 2: wd=0.1, it=10 | val_loss=0.2972, test_acc=98.60%\n",
      "\n",
      "===== Fold 3/10 =====\n",
      "Fold 3 | wd=0.1, it=10 | val_loss=0.3178, test_acc=98.83%\n",
      "** Best in Fold 3: wd=0.1, it=10 | val_loss=0.3178, test_acc=98.83%\n",
      "\n",
      "===== Fold 4/10 =====\n",
      "Fold 4 | wd=0.1, it=10 | val_loss=0.3011, test_acc=98.47%\n",
      "** Best in Fold 4: wd=0.1, it=10 | val_loss=0.3011, test_acc=98.47%\n",
      "\n",
      "===== Fold 5/10 =====\n",
      "Fold 5 | wd=0.1, it=10 | val_loss=0.3022, test_acc=98.57%\n",
      "** Best in Fold 5: wd=0.1, it=10 | val_loss=0.3022, test_acc=98.57%\n",
      "\n",
      "===== Fold 6/10 =====\n",
      "Fold 6 | wd=0.1, it=10 | val_loss=0.3072, test_acc=98.73%\n",
      "** Best in Fold 6: wd=0.1, it=10 | val_loss=0.3072, test_acc=98.73%\n",
      "\n",
      "===== Fold 7/10 =====\n",
      "Fold 7 | wd=0.1, it=10 | val_loss=0.3189, test_acc=98.67%\n",
      "** Best in Fold 7: wd=0.1, it=10 | val_loss=0.3189, test_acc=98.67%\n",
      "\n",
      "===== Fold 8/10 =====\n",
      "Fold 8 | wd=0.1, it=10 | val_loss=0.3139, test_acc=98.70%\n",
      "** Best in Fold 8: wd=0.1, it=10 | val_loss=0.3139, test_acc=98.70%\n",
      "\n",
      "===== Fold 9/10 =====\n",
      "Fold 9 | wd=0.1, it=10 | val_loss=0.3044, test_acc=98.73%\n",
      "** Best in Fold 9: wd=0.1, it=10 | val_loss=0.3044, test_acc=98.73%\n",
      "\n",
      "===== Fold 10/10 =====\n",
      "Fold 10 | wd=0.1, it=10 | val_loss=0.3211, test_acc=98.90%\n",
      "** Best in Fold 10: wd=0.1, it=10 | val_loss=0.3211, test_acc=98.90%\n",
      "\n",
      "==== 10-Fold Cross Validation Result ====\n",
      "Mean Val Loss: 0.3088\n",
      "Mean Test Accuracy: 98.68% ± 0.12%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3087777777777778, 0.9868333333333335)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_and_report_coteach_plus_cv(\n",
    "    dataset_path=DATASET_1,\n",
    "    lr=1e-3,\n",
    "    it_values=(10,),\n",
    "    wd_values=(1e-1,),\n",
    "    seed=42,\n",
    "    final_forget=0.3,\n",
    "    sched='linear',\n",
    "    p_drop=0.5,\n",
    "    num_folds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f87ea81e-9c5b-4b8b-82ff-e761a6b3dc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== 10-Fold CV on Dataset: datasets/FashionMNIST0.6.npz ====\n",
      "\n",
      "===== Fold 1/10 =====\n",
      "Fold 1 | wd=0.5, it=30 | val_loss=0.6133, test_acc=96.33%\n",
      "** Best in Fold 1: wd=0.5, it=30 | val_loss=0.6133, test_acc=96.33%\n",
      "\n",
      "===== Fold 2/10 =====\n",
      "Fold 2 | wd=0.5, it=30 | val_loss=0.6061, test_acc=95.63%\n",
      "** Best in Fold 2: wd=0.5, it=30 | val_loss=0.6061, test_acc=95.63%\n",
      "\n",
      "===== Fold 3/10 =====\n",
      "Fold 3 | wd=0.5, it=30 | val_loss=0.6200, test_acc=97.53%\n",
      "** Best in Fold 3: wd=0.5, it=30 | val_loss=0.6200, test_acc=97.53%\n",
      "\n",
      "===== Fold 4/10 =====\n",
      "Fold 4 | wd=0.5, it=30 | val_loss=0.6233, test_acc=96.57%\n",
      "** Best in Fold 4: wd=0.5, it=30 | val_loss=0.6233, test_acc=96.57%\n",
      "\n",
      "===== Fold 5/10 =====\n",
      "Fold 5 | wd=0.5, it=30 | val_loss=0.6139, test_acc=95.90%\n",
      "** Best in Fold 5: wd=0.5, it=30 | val_loss=0.6139, test_acc=95.90%\n",
      "\n",
      "===== Fold 6/10 =====\n",
      "Fold 6 | wd=0.5, it=30 | val_loss=0.5961, test_acc=95.47%\n",
      "** Best in Fold 6: wd=0.5, it=30 | val_loss=0.5961, test_acc=95.47%\n",
      "\n",
      "===== Fold 7/10 =====\n",
      "Fold 7 | wd=0.5, it=30 | val_loss=0.6156, test_acc=95.50%\n",
      "** Best in Fold 7: wd=0.5, it=30 | val_loss=0.6156, test_acc=95.50%\n",
      "\n",
      "===== Fold 8/10 =====\n",
      "Fold 8 | wd=0.5, it=30 | val_loss=0.5928, test_acc=95.90%\n",
      "** Best in Fold 8: wd=0.5, it=30 | val_loss=0.5928, test_acc=95.90%\n",
      "\n",
      "===== Fold 9/10 =====\n",
      "Fold 9 | wd=0.5, it=30 | val_loss=0.6111, test_acc=96.73%\n",
      "** Best in Fold 9: wd=0.5, it=30 | val_loss=0.6111, test_acc=96.73%\n",
      "\n",
      "===== Fold 10/10 =====\n",
      "Fold 10 | wd=0.5, it=30 | val_loss=0.6494, test_acc=64.93%\n",
      "** Best in Fold 10: wd=0.5, it=30 | val_loss=0.6494, test_acc=64.93%\n",
      "\n",
      "==== 10-Fold Cross Validation Result ====\n",
      "Mean Val Loss: 0.6142\n",
      "Mean Test Accuracy: 93.05% ± 9.39%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6141666666666665, 0.9305)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_and_report_coteach_plus_cv(\n",
    "    dataset_path=DATASET_2,\n",
    "    lr=1e-4,\n",
    "    it_values=(30,),\n",
    "    wd_values=(5e-1,),\n",
    "    seed=42,\n",
    "    final_forget=0.75,\n",
    "    sched='linear',\n",
    "    p_drop=0.5,\n",
    "    num_folds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90f6e765-2535-4578-af1b-bb5ec9f4594f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== 10-Fold CV on Dataset: datasets/CIFAR.npz ====\n",
      "\n",
      "===== Fold 1/10 =====\n",
      "Fold 1 | wd=0.5, it=30 | val_loss=0.6113, test_acc=65.23%\n",
      "** Best in Fold 1: wd=0.5, it=30 | val_loss=0.6113, test_acc=65.23%\n",
      "\n",
      "===== Fold 2/10 =====\n",
      "Fold 2 | wd=0.5, it=30 | val_loss=0.6200, test_acc=68.43%\n",
      "** Best in Fold 2: wd=0.5, it=30 | val_loss=0.6200, test_acc=68.43%\n",
      "\n",
      "===== Fold 3/10 =====\n",
      "Fold 3 | wd=0.5, it=30 | val_loss=0.6213, test_acc=65.53%\n",
      "** Best in Fold 3: wd=0.5, it=30 | val_loss=0.6213, test_acc=65.53%\n",
      "\n",
      "===== Fold 4/10 =====\n",
      "Fold 4 | wd=0.5, it=30 | val_loss=0.6280, test_acc=61.07%\n",
      "** Best in Fold 4: wd=0.5, it=30 | val_loss=0.6280, test_acc=61.07%\n",
      "\n",
      "===== Fold 5/10 =====\n",
      "Fold 5 | wd=0.5, it=30 | val_loss=0.6207, test_acc=64.37%\n",
      "** Best in Fold 5: wd=0.5, it=30 | val_loss=0.6207, test_acc=64.37%\n",
      "\n",
      "===== Fold 6/10 =====\n",
      "Fold 6 | wd=0.5, it=30 | val_loss=0.6153, test_acc=56.40%\n",
      "** Best in Fold 6: wd=0.5, it=30 | val_loss=0.6153, test_acc=56.40%\n",
      "\n",
      "===== Fold 7/10 =====\n",
      "Fold 7 | wd=0.5, it=30 | val_loss=0.6327, test_acc=64.63%\n",
      "** Best in Fold 7: wd=0.5, it=30 | val_loss=0.6327, test_acc=64.63%\n",
      "\n",
      "===== Fold 8/10 =====\n",
      "Fold 8 | wd=0.5, it=30 | val_loss=0.6280, test_acc=62.80%\n",
      "** Best in Fold 8: wd=0.5, it=30 | val_loss=0.6280, test_acc=62.80%\n",
      "\n",
      "===== Fold 9/10 =====\n",
      "Fold 9 | wd=0.5, it=30 | val_loss=0.6307, test_acc=61.73%\n",
      "** Best in Fold 9: wd=0.5, it=30 | val_loss=0.6307, test_acc=61.73%\n",
      "\n",
      "===== Fold 10/10 =====\n",
      "Fold 10 | wd=0.5, it=30 | val_loss=0.6007, test_acc=60.67%\n",
      "** Best in Fold 10: wd=0.5, it=30 | val_loss=0.6007, test_acc=60.67%\n",
      "\n",
      "==== 10-Fold Cross Validation Result ====\n",
      "Mean Val Loss: 0.6209\n",
      "Mean Test Accuracy: 63.09% ± 3.16%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6208666666666668, 0.6308666666666667)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_and_report_coteach_plus_cv(\n",
    "    dataset_path=DATASET_3,\n",
    "    lr=1e-4,\n",
    "    it_values=(30,), \n",
    "    wd_values=(5e-1,),\n",
    "    seed=42,\n",
    "    final_forget=0.74,\n",
    "    sched='linear',\n",
    "    p_drop=0.5,\n",
    "    num_folds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f48ad2e-3bb0-471b-bd3f-cb52583f28b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

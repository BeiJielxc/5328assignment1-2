{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4140ef1c",
   "metadata": {},
   "source": [
    "# Co-Teaching with CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff2ad85-03a6-4935-b480-5aecf2b56ad2",
   "metadata": {},
   "source": [
    "Running instruction:\n",
    "1) Run all the defining function From Part 1-3\n",
    "2) For Grid-search for hyperparameter tunning, run Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f83eff-a756-4936-849b-349f336f03ba",
   "metadata": {},
   "source": [
    "# 1.Impore package and load GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f54ebb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "# ==== Deterministic setup (reproducibility) ====\n",
    "import os, random, numpy as np, torch, math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PIN_MEMORY = bool(torch.cuda.is_available())\n",
    "NUM_WORKERS = 0  # keep 0 to avoid multi-process RNG issues unless necessary\n",
    "\n",
    "# Make cuDNN deterministic globally\n",
    "try:\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "except Exception as _e:\n",
    "    pass\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    try:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    except Exception as _e:\n",
    "        pass\n",
    "print(\"Device:\", DEVICE)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d5a4f0-23cf-4d34-aebe-03e9aeeb335f",
   "metadata": {},
   "source": [
    "# 2.Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1c4999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    import os, random, numpy as np, torch\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def _infer_hw_c_from_flat_dim(D:int):\n",
    "    s = int(np.sqrt(D) + 1e-8)\n",
    "    if s*s == D: return s, s, 1\n",
    "    if D % 3 == 0:\n",
    "        s3 = int(np.sqrt(D//3) + 1e-8)\n",
    "        if s3*s3*3 == D: return s3, s3, 3\n",
    "    return None, None, None\n",
    "\n",
    "def load_npz(path:str):\n",
    "    d = np.load(path)\n",
    "    Xtr, Str = d[\"Xtr\"], d[\"Str\"]\n",
    "    Xts, Yts = d[\"Xts\"], d[\"Yts\"]\n",
    "    if Xtr.ndim == 4 and Xtr.shape[-1]==3: H,W,C = Xtr.shape[1], Xtr.shape[2], 3\n",
    "    elif Xtr.ndim == 3: H,W,C = Xtr.shape[1], Xtr.shape[2], 1\n",
    "    elif Xtr.ndim == 2:\n",
    "        H,W,C = _infer_hw_c_from_flat_dim(Xtr.shape[1])\n",
    "        if H is None: raise ValueError(\"Cannot infer HWC\")\n",
    "    else: raise ValueError(f\"Bad shape: {Xtr.shape}\")\n",
    "    num_classes = int(max(Str.max(), Yts.max())+1)\n",
    "    return (Xtr, Str, Xts, Yts, (H,W,C), num_classes)\n",
    "\n",
    "class NPZImageDataset(Dataset):\n",
    "    def __init__(self, X, y, shape_hw_c):\n",
    "        X = X.astype(np.float32)\n",
    "        H,W,C = shape_hw_c\n",
    "        if X.ndim == 2:\n",
    "            X = X.reshape(-1,H,W) if C==1 else X.reshape(-1,H,W,C)\n",
    "        if X.max()>1.5: X = X/255.0\n",
    "        if X.ndim == 3: X = X[:,None,:,:]\n",
    "        elif X.ndim == 4: X = np.transpose(X,(0,3,1,2))\n",
    "        X = (X - X.mean())/(X.std()+1e-6)\n",
    "        self.X, self.y = X, y.astype(np.int64)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self,i): return torch.from_numpy(self.X[i]), int(self.y[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a613d9-e21d-4ba4-8412-d1a2c4165293",
   "metadata": {},
   "source": [
    "# 3.Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305fa2f3-ee7e-4acf-986e-d7c09376a68e",
   "metadata": {},
   "source": [
    "## 3.1 Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "939d3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_BN_Drop(nn.Module):\n",
    "    def __init__(self, in_ch=1, num_classes=10, p_drop=0.4):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(p_drop),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(p_drop),\n",
    "        )\n",
    "        self.adapt = nn.AdaptiveAvgPool2d((7,7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*7*7, 256), nn.ReLU(),\n",
    "            nn.Dropout(p_drop),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = self.adapt(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "def make_model(in_ch, C, p_drop=0.4):\n",
    "    return CNN_BN_Drop(in_ch=in_ch, num_classes=C, p_drop=p_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7646eeee-7918-41b4-93bc-8f26f5e750df",
   "metadata": {},
   "source": [
    "## 3.2.Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b91a513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_indices_by_small_loss(logits, y, keep_ratio):\n",
    "    losses = F.cross_entropy(logits, y, reduction='none')\n",
    "    k = max(1, int(keep_ratio * len(losses)))\n",
    "    return torch.topk(-losses, k=k).indices\n",
    "\n",
    "def coteach_epoch(model1, model2, loader, opt1, opt2, keep_ratio):\n",
    "    model1.train(); model2.train(); total=0.0\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "        l1, l2 = model1(x), model2(x)\n",
    "        idx1 = topk_indices_by_small_loss(l1, y, keep_ratio)\n",
    "        idx2 = topk_indices_by_small_loss(l2, y, keep_ratio)\n",
    "        loss1 = F.cross_entropy(l1[idx2], y[idx2])\n",
    "        loss2 = F.cross_entropy(l2[idx1], y[idx1])\n",
    "        opt1.zero_grad(); loss1.backward(); opt1.step()\n",
    "        opt2.zero_grad(); loss2.backward(); opt2.step()\n",
    "        total += (loss1.item()+loss2.item())/2\n",
    "    return total/len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval(); corr=0; tot=0\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "        pred = model(x).argmax(1)\n",
    "        corr += (pred==y).sum().item(); tot += y.size(0)\n",
    "    return corr/tot\n",
    "\n",
    "def linear_schedule(epoch, max_epoch, final_forget):\n",
    "    return min(final_forget, final_forget * epoch / max(1, max_epoch))\n",
    "\n",
    "def cosine_schedule(epoch, max_epoch, final_forget):\n",
    "    t = epoch / max(1, max_epoch)\n",
    "    return final_forget * (0.5 - 0.5*math.cos(math.pi * t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9990600-737f-47ab-ba47-7482813e644c",
   "metadata": {},
   "source": [
    "## 3.3.Main Function ( pipeline for run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0567310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_config_coteach_scheduled(\n",
    "    dataset_path, epochs, wd, lr, seed=2025,\n",
    "    final_forget=0.6, sched='linear', p_drop=0.4,\n",
    "    warmup_epochs=8,\n",
    "    tr_idx=None, va_idx=None,\n",
    "    generator=None\n",
    "):\n",
    "    # set seed\n",
    "    set_seed(seed)\n",
    "\n",
    "    # load data\n",
    "    Xtr, Str, Xts, Yts, hwc, C = load_npz(dataset_path)\n",
    "\n",
    "    # if no idx,use hold-out validation\n",
    "    if tr_idx is None or va_idx is None:\n",
    "        tr_idx, va_idx = train_test_split(\n",
    "            np.arange(len(Str)), test_size=0.1, stratify=Str, random_state=seed\n",
    "        )\n",
    "\n",
    "    # construct the train, val, test dataset\n",
    "    tr = NPZImageDataset(Xtr[tr_idx], Str[tr_idx], shape_hw_c=hwc)\n",
    "    va = NPZImageDataset(Xtr[va_idx], Str[va_idx], shape_hw_c=hwc)\n",
    "    ts = NPZImageDataset(Xts, Yts, shape_hw_c=hwc)\n",
    "\n",
    "    # DataLoader\n",
    "    tr_loader = DataLoader(tr, batch_size=256, shuffle=True,\n",
    "                           num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
    "                           generator=generator)\n",
    "    va_loader = DataLoader(va, batch_size=256, shuffle=False,\n",
    "                           num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "    ts_loader = DataLoader(ts, batch_size=256, shuffle=False,\n",
    "                           num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "    # init model and optimizor\n",
    "    in_ch = hwc[2]\n",
    "    m1 = make_model(in_ch, C, p_drop).to(DEVICE)\n",
    "    m2 = make_model(in_ch, C, p_drop).to(DEVICE)\n",
    "    opt1 = torch.optim.AdamW(m1.parameters(), lr=lr, weight_decay=wd)\n",
    "    opt2 = torch.optim.AdamW(m2.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    # Train\n",
    "    for ep in range(1, epochs + 1):\n",
    "        if ep <= warmup_epochs:\n",
    "            m1.train(); m2.train()\n",
    "            for x, y in tr_loader:\n",
    "                x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "                opt1.zero_grad(set_to_none=True)\n",
    "                F.cross_entropy(m1(x), y).backward()\n",
    "                opt1.step()\n",
    "                opt2.zero_grad(set_to_none=True)\n",
    "                F.cross_entropy(m2(x), y).backward()\n",
    "                opt2.step()\n",
    "            continue\n",
    "\n",
    "        # Warmup then go into Co-Teaching\n",
    "        t_ep = ep - warmup_epochs\n",
    "        T_total = max(1, epochs - warmup_epochs)\n",
    "        if sched == 'cosine':\n",
    "            forget = cosine_schedule(t_ep, T_total, final_forget)\n",
    "        else:\n",
    "            forget = linear_schedule(t_ep, T_total, final_forget)\n",
    "\n",
    "        keep_ratio = float(min(1.0, max(0.0, 1.0 - forget)))\n",
    "        coteach_epoch(m1, m2, tr_loader, opt1, opt2, keep_ratio)\n",
    "\n",
    "    # evaluation\n",
    "    va_acc = max(evaluate(m1, va_loader), evaluate(m2, va_loader))\n",
    "    ts_acc = max(evaluate(m1, ts_loader), evaluate(m2, ts_loader))\n",
    "    val_loss = 1.0 - va_acc\n",
    "    return val_loss, ts_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba743aeb-ca27-48aa-9dbe-c4cf92f85233",
   "metadata": {},
   "source": [
    "## 3.4 Pipeline for Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03837937-c2a9-4b0c-83d6-68ad694b672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def tune_and_report_coteach_plus_cv(\n",
    "    dataset_path,\n",
    "    lr=1e-3,\n",
    "    it_values=(30,),\n",
    "    wd_values=(5e-2,),\n",
    "    seed=42,\n",
    "    final_forget=0.6,\n",
    "    sched='linear',\n",
    "    p_drop=0.5,\n",
    "    num_folds=10\n",
    "):\n",
    "    print(f\"==== 10-Fold CV on Dataset: {dataset_path} ====\")\n",
    "\n",
    "    # set seed \n",
    "    set_seed(seed)\n",
    "\n",
    "    # load data\n",
    "    Xtr, Str, Xts, Yts, hwc, C = load_npz(dataset_path)\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    fold_accs, fold_losses = [], []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(Xtr)):\n",
    "        print(f\"\\n===== Fold {fold + 1}/{num_folds} =====\")\n",
    "        # each fold have generator\n",
    "        g = torch.Generator(device='cpu').manual_seed(seed + fold)\n",
    "\n",
    "        best = None\n",
    "        for it in it_values:\n",
    "            for wd in wd_values:\n",
    "                vloss, tacc = train_config_coteach_scheduled(\n",
    "                    dataset_path=dataset_path,\n",
    "                    epochs=it, wd=wd, lr=lr,\n",
    "                    seed=seed + fold,              \n",
    "                    final_forget=final_forget,\n",
    "                    sched=sched,\n",
    "                    p_drop=p_drop,\n",
    "                    tr_idx=train_idx, va_idx=val_idx,\n",
    "                    generator=g\n",
    "                )\n",
    "                print(f\"Fold {fold+1} | wd={wd}, it={it} | val_loss={vloss:.4f}, test_acc={tacc*100:.2f}%\")\n",
    "\n",
    "                if (best is None) or (vloss < best[0] - 1e-12) or (abs(vloss - best[0]) < 1e-12 and tacc > best[1]):\n",
    "                    best = (vloss, tacc, wd, it)\n",
    "\n",
    "        fold_losses.append(best[0])\n",
    "        fold_accs.append(best[1])\n",
    "\n",
    "    mean_acc = float(np.mean(fold_accs))\n",
    "    std_acc  = float(np.std(fold_accs))\n",
    "    mean_loss = float(np.mean(fold_losses))\n",
    "\n",
    "    print(\"\\n==== 10-Fold Cross Validation Result ====\")\n",
    "    print(f\"Mean Val Loss: {mean_loss:.4f}\")\n",
    "    print(f\"Mean Test Accuracy: {mean_acc*100:.2f}% ± {std_acc*100:.2f}%\")\n",
    "    return mean_loss, mean_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a1f206-04cb-44a5-9140-47015554fd8f",
   "metadata": {},
   "source": [
    "# 4.Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47018edc-cadc-4d88-b2aa-d75367805ff8",
   "metadata": {},
   "source": [
    "## 4.1 define the frid search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d640fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_report_coteach_plus(dataset_path, lr=1e-3, it_values=(500,), wd_values=(1e-4,1e-3,5e-2,1e-2,5e-1,1e-1),\n",
    "                                 seed=42, final_forget=0.6, sched='linear', p_drop=0.4):\n",
    "    print(f\"==== Dataset: {dataset_path} ====\")\n",
    "    print(\"Tuned configs (both orientations):\")\n",
    "    best=None\n",
    "    for it in it_values:\n",
    "        for wd in wd_values:\n",
    "            vloss,tacc = train_config_coteach_scheduled(dataset_path, epochs=it, wd=wd, lr=lr, seed=seed,\n",
    "                                                        final_forget=final_forget, sched=sched, p_drop=p_drop)\n",
    "            print(f\"wd={wd}, it={it} | val_loss={vloss:.4f}, test_acc={tacc*100:.2f}%\")\n",
    "            if (best is None) or (vloss<best[0]-1e-12) or (abs(vloss-best[0])<1e-12 and tacc>best[1]):\n",
    "                best=(vloss,tacc,wd,it)\n",
    "    print(f\"** Best: wd={best[2]}, it={best[3]} | val_loss={best[0]:.4f}, test_acc={best[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbfd256-06b5-459b-9c81-f291416c96fc",
   "metadata": {},
   "source": [
    "## 4.2 load specific data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "803f2398-a035-4890-b8dd-e0717196ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the routh\n",
    "DATASET_1 = \"datasets/FashionMNIST0.3.npz\"\n",
    "DATASET_2 = \"datasets/FashionMNIST0.6.npz\"\n",
    "DATASET_3 = \"datasets/CIFAR.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca1dad-d85c-4bd9-8f64-932c076ccb74",
   "metadata": {},
   "source": [
    "## 4.3 The process for tuning hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa1520e5-ae3f-4669-9a91-c7855d766d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Dataset: datasets/FashionMNIST0.3.npz ====\n",
      "Tuned configs (both orientations):\n",
      "wd=0.05, it=10 | val_loss=0.3117, test_acc=98.07%\n",
      "wd=0.01, it=10 | val_loss=0.3128, test_acc=98.77%\n",
      "wd=0.5, it=10 | val_loss=0.3128, test_acc=98.23%\n",
      "wd=0.1, it=10 | val_loss=0.3111, test_acc=98.80%\n",
      "** Best: wd=0.1, it=10 | val_loss=0.3111, test_acc=98.80%\n"
     ]
    }
   ],
   "source": [
    "tune_and_report_coteach_plus(\n",
    "    DATASET_1, \n",
    "    lr=1e-3, \n",
    "    it_values=(10,),\n",
    "    wd_values=(5e-2,1e-2,5e-1,1e-1), \n",
    "    seed=42,\n",
    "    final_forget=0.3, \n",
    "    sched='linear', \n",
    "    p_drop=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a201c75b-4725-47b7-96bd-b58b75aed0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Dataset: datasets/FashionMNIST0.6.npz ====\n",
      "Tuned configs (both orientations):\n",
      "wd=0.0001, it=30 | val_loss=0.6311, test_acc=95.83%\n",
      "wd=0.5, it=30 | val_loss=0.6317, test_acc=96.07%\n",
      "wd=0.1, it=30 | val_loss=0.6289, test_acc=96.50%\n",
      "** Best: wd=0.1, it=30 | val_loss=0.6289, test_acc=96.50%\n"
     ]
    }
   ],
   "source": [
    "tune_and_report_coteach_plus(\n",
    "    DATASET_2, \n",
    "    lr=1e-4, \n",
    "    it_values=(30,),\n",
    "    wd_values=(1e-4,5e-1,1e-1,), \n",
    "    seed=42,\n",
    "    final_forget=0.75, \n",
    "    sched='linear', \n",
    "    p_drop=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbd7c10a-4303-4925-8ba6-8cb38f582d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Dataset: datasets/CIFAR.npz ====\n",
      "Tuned configs (both orientations):\n",
      "wd=0.05, it=10 | val_loss=0.6153, test_acc=51.40%\n",
      "wd=0.0001, it=10 | val_loss=0.6667, test_acc=33.33%\n",
      "wd=0.5, it=10 | val_loss=0.6333, test_acc=48.43%\n",
      "wd=0.1, it=10 | val_loss=0.6167, test_acc=51.50%\n",
      "** Best: wd=0.05, it=10 | val_loss=0.6153, test_acc=51.40%\n"
     ]
    }
   ],
   "source": [
    "tune_and_report_coteach_plus(\n",
    "    DATASET_3,\n",
    "    lr=1e-4, \n",
    "    it_values=(10,), \n",
    "    wd_values=(5e-2,1e-4,5e-1,1e-1),\n",
    "    seed=42, \n",
    "    final_forget=0.74,\n",
    "    sched='linear', \n",
    "    p_drop=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7056310-2785-4f96-bf19-8c13de8b39a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Dataset: datasets/CIFAR.npz ====\n",
      "Tuned configs (both orientations):\n",
      "wd=0.05, it=10 | val_loss=0.6273, test_acc=44.13%\n",
      "wd=0.05, it=20 | val_loss=0.6107, test_acc=58.40%\n",
      "wd=0.05, it=30 | val_loss=0.5920, test_acc=70.60%\n",
      "** Best: wd=0.05, it=30 | val_loss=0.5920, test_acc=70.60%\n"
     ]
    }
   ],
   "source": [
    "tune_and_report_coteach_plus(\n",
    "    DATASET_3,\n",
    "    lr=1e-4, \n",
    "    it_values=(10,20,30), \n",
    "    wd_values=(5e-2,),\n",
    "    seed=42, \n",
    "    final_forget=0.74,\n",
    "    sched='linear', \n",
    "    p_drop=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0a3afe-4434-4b48-8f9a-f22b01e619ea",
   "metadata": {},
   "source": [
    "## 4.4 Best hyperparameter for 10-fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b6d57c-06e7-4570-9c81-466370c0cccf",
   "metadata": {},
   "source": [
    "### 4.4.1 Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "046f5f6d-c931-4c96-8b72-007f31042c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== 10-Fold CV on Dataset: datasets/FashionMNIST0.3.npz ====\n",
      "\n",
      "===== Fold 1/10 =====\n",
      "Fold 1 | wd=0.1, it=10 | val_loss=0.3039, test_acc=98.63%\n",
      "\n",
      "===== Fold 2/10 =====\n",
      "Fold 2 | wd=0.1, it=10 | val_loss=0.2972, test_acc=98.60%\n",
      "\n",
      "===== Fold 3/10 =====\n",
      "Fold 3 | wd=0.1, it=10 | val_loss=0.3178, test_acc=98.83%\n",
      "\n",
      "===== Fold 4/10 =====\n",
      "Fold 4 | wd=0.1, it=10 | val_loss=0.3011, test_acc=98.47%\n",
      "\n",
      "===== Fold 5/10 =====\n",
      "Fold 5 | wd=0.1, it=10 | val_loss=0.3022, test_acc=98.57%\n",
      "\n",
      "===== Fold 6/10 =====\n",
      "Fold 6 | wd=0.1, it=10 | val_loss=0.3072, test_acc=98.73%\n",
      "\n",
      "===== Fold 7/10 =====\n",
      "Fold 7 | wd=0.1, it=10 | val_loss=0.3189, test_acc=98.67%\n",
      "\n",
      "===== Fold 8/10 =====\n",
      "Fold 8 | wd=0.1, it=10 | val_loss=0.3139, test_acc=98.70%\n",
      "\n",
      "===== Fold 9/10 =====\n",
      "Fold 9 | wd=0.1, it=10 | val_loss=0.3044, test_acc=98.73%\n",
      "\n",
      "===== Fold 10/10 =====\n",
      "Fold 10 | wd=0.1, it=10 | val_loss=0.3211, test_acc=98.90%\n",
      "\n",
      "==== 10-Fold Cross Validation Result ====\n",
      "Mean Val Loss: 0.3088\n",
      "Mean Test Accuracy: 98.68% ± 0.12%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3087777777777778, 0.9868333333333335)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_and_report_coteach_plus_cv(\n",
    "    dataset_path=DATASET_1,\n",
    "    lr=1e-3,\n",
    "    it_values=(10,),\n",
    "    wd_values=(1e-1,),\n",
    "    seed=42,\n",
    "    final_forget=0.3,\n",
    "    sched='linear',\n",
    "    p_drop=0.5,\n",
    "    num_folds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26e08f8-5852-444f-ac5c-7efd8faccd7d",
   "metadata": {},
   "source": [
    "### 4.4.2 Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f87ea81e-9c5b-4b8b-82ff-e761a6b3dc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== 10-Fold CV on Dataset: datasets/FashionMNIST0.6.npz ====\n",
      "\n",
      "===== Fold 1/10 =====\n",
      "Fold 1 | wd=0.1, it=30 | val_loss=0.6133, test_acc=96.23%\n",
      "\n",
      "===== Fold 2/10 =====\n",
      "Fold 2 | wd=0.1, it=30 | val_loss=0.6033, test_acc=97.03%\n",
      "\n",
      "===== Fold 3/10 =====\n",
      "Fold 3 | wd=0.1, it=30 | val_loss=0.6178, test_acc=96.57%\n",
      "\n",
      "===== Fold 4/10 =====\n",
      "Fold 4 | wd=0.1, it=30 | val_loss=0.6244, test_acc=96.47%\n",
      "\n",
      "===== Fold 5/10 =====\n",
      "Fold 5 | wd=0.1, it=30 | val_loss=0.6144, test_acc=95.83%\n",
      "\n",
      "===== Fold 6/10 =====\n",
      "Fold 6 | wd=0.1, it=30 | val_loss=0.5972, test_acc=95.97%\n",
      "\n",
      "===== Fold 7/10 =====\n",
      "Fold 7 | wd=0.1, it=30 | val_loss=0.6139, test_acc=95.87%\n",
      "\n",
      "===== Fold 8/10 =====\n",
      "Fold 8 | wd=0.1, it=30 | val_loss=0.5917, test_acc=96.67%\n",
      "\n",
      "===== Fold 9/10 =====\n",
      "Fold 9 | wd=0.1, it=30 | val_loss=0.6117, test_acc=96.80%\n",
      "\n",
      "===== Fold 10/10 =====\n",
      "Fold 10 | wd=0.1, it=30 | val_loss=0.6044, test_acc=96.27%\n",
      "\n",
      "==== 10-Fold Cross Validation Result ====\n",
      "Mean Val Loss: 0.6092\n",
      "Mean Test Accuracy: 96.37% ± 0.39%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6092222222222222, 0.9637)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_and_report_coteach_plus_cv(\n",
    "    dataset_path=DATASET_2,\n",
    "    lr=1e-4,\n",
    "    it_values=(30,),\n",
    "    wd_values=(1e-1,),\n",
    "    seed=42,\n",
    "    final_forget=0.75,\n",
    "    sched='linear',\n",
    "    p_drop=0.5,\n",
    "    num_folds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc269d82-3c03-4dc6-aa35-a7ffb8ddaf65",
   "metadata": {},
   "source": [
    "### 4.4.3 Dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90f6e765-2535-4578-af1b-bb5ec9f4594f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== 10-Fold CV on Dataset: datasets/CIFAR.npz ====\n",
      "\n",
      "===== Fold 1/10 =====\n",
      "Fold 1 | wd=0.05, it=30 | val_loss=0.6000, test_acc=60.83%\n",
      "\n",
      "===== Fold 2/10 =====\n",
      "Fold 2 | wd=0.05, it=30 | val_loss=0.6240, test_acc=67.47%\n",
      "\n",
      "===== Fold 3/10 =====\n",
      "Fold 3 | wd=0.05, it=30 | val_loss=0.6273, test_acc=62.63%\n",
      "\n",
      "===== Fold 4/10 =====\n",
      "Fold 4 | wd=0.05, it=30 | val_loss=0.6133, test_acc=68.77%\n",
      "\n",
      "===== Fold 5/10 =====\n",
      "Fold 5 | wd=0.05, it=30 | val_loss=0.6127, test_acc=66.40%\n",
      "\n",
      "===== Fold 6/10 =====\n",
      "Fold 6 | wd=0.05, it=30 | val_loss=0.6140, test_acc=56.07%\n",
      "\n",
      "===== Fold 7/10 =====\n",
      "Fold 7 | wd=0.05, it=30 | val_loss=0.6247, test_acc=74.97%\n",
      "\n",
      "===== Fold 8/10 =====\n",
      "Fold 8 | wd=0.05, it=30 | val_loss=0.6227, test_acc=64.07%\n",
      "\n",
      "===== Fold 9/10 =====\n",
      "Fold 9 | wd=0.05, it=30 | val_loss=0.6173, test_acc=66.60%\n",
      "\n",
      "===== Fold 10/10 =====\n",
      "Fold 10 | wd=0.05, it=30 | val_loss=0.6053, test_acc=65.97%\n",
      "\n",
      "==== 10-Fold Cross Validation Result ====\n",
      "Mean Val Loss: 0.6161\n",
      "Mean Test Accuracy: 65.38% ± 4.77%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6161333333333332, 0.6537666666666666)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_and_report_coteach_plus_cv(\n",
    "    dataset_path=DATASET_3,\n",
    "    lr=1e-4,\n",
    "    it_values=(30,), \n",
    "    wd_values=(5e-2,),\n",
    "    seed=42,\n",
    "    final_forget=0.74,\n",
    "    sched='linear',\n",
    "    p_drop=0.5,\n",
    "    num_folds=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7678c661",
   "metadata": {},
   "source": [
    "## 一、导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "996c890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "import random\n",
    "import scipy.optimize as opt\n",
    "import scipy.linalg as sla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309191eb",
   "metadata": {},
   "source": [
    "## 二、数据读取与处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd07528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载（复用作业给的风格）\n",
    "@dataclass\n",
    "class Dataset:\n",
    "    Xtr: np.ndarray  # noisy train+val 的特征\n",
    "    Str: np.ndarray  # noisy train+val 的标签（{0,1,2}）\n",
    "    Xts: np.ndarray  # clean test 的特征\n",
    "    Yts: np.ndarray  # clean test 的标签（{0,1,2}）\n",
    "\n",
    "def load_npz(path): \n",
    "    d=np.load(path); \n",
    "    return Dataset(d['Xtr'],d['Str'],d['Xts'],d['Yts'])\n",
    "\n",
    "#其他函数定义\n",
    "def set_seed(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "def one_hot(y: np.ndarray, C: int) -> np.ndarray:\n",
    "    oh = np.zeros((y.shape[0], C), dtype=np.float32)\n",
    "    oh[np.arange(y.shape[0]), y] = 1.0\n",
    "    return oh\n",
    "\n",
    "def softmax(z: np.ndarray) -> np.ndarray:\n",
    "    # 数值稳定\n",
    "    z = z - z.max(axis=1, keepdims=True)\n",
    "    expz = np.exp(z)\n",
    "    return expz / (expz.sum(axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "def accuracy(y, yhat): return float((y==yhat).mean())\n",
    "\n",
    "\n",
    "#根据文件名返回已知的转移矩阵 T。\n",
    "def get_T(name: str) -> np.ndarray:\n",
    "    name = name.lower()\n",
    "    if \"0.3\" in name:\n",
    "        T = np.array([[0.7, 0.3, 0.0],\n",
    "                      [0.0, 0.7, 0.3],\n",
    "                      [0.3, 0.0, 0.7]], dtype=np.float32)\n",
    "    elif \"0.6\" in name:\n",
    "        T = np.array([[0.4, 0.3, 0.3],\n",
    "                      [0.3, 0.4, 0.3],\n",
    "                      [0.3, 0.3, 0.4]], dtype=np.float32)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown dataset: only 0.3 and 0.6 are supported here.\")\n",
    "    return T\n",
    "\n",
    "# 训练集划分\n",
    "def split(X,y,ratio=0.2,seed=42):\n",
    "    set_seed(seed); \n",
    "    n=X.shape[0]; \n",
    "    idx=np.random.permutation(n); \n",
    "    sp=int(n*(1-ratio))\n",
    "    return X[idx[:sp]],y[idx[:sp]],X[idx[sp:]],y[idx[sp:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2611ddf3",
   "metadata": {},
   "source": [
    "## 三、ccn算法实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec29a327",
   "metadata": {},
   "source": [
    "### prepocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ecb9e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Standardizer:\n",
    "    mean: np.ndarray; std: np.ndarray\n",
    "    def transform(self,Xf):\n",
    "        Xn=(Xf-self.mean)/self.std\n",
    "        bias=np.ones((Xn.shape[0],1),dtype=np.float64)\n",
    "        return np.hstack([Xn,bias])\n",
    "\n",
    "def flatten(X): \n",
    "    return X.reshape(X.shape[0],-1).astype(np.float64)\n",
    "def fit_std(Xtrf): \n",
    "    m=Xtrf.mean(0,keepdims=True); \n",
    "    s=Xtrf.std(0,keepdims=True)+1e-5; \n",
    "    return Standardizer(m,s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62631634",
   "metadata": {},
   "source": [
    "### forward方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33141501",
   "metadata": {},
   "source": [
    "Forward 方法：把「干净预测分布」p_clean 乘以 T^T，得到 noisy 标签的预测分布：p_tilde = T^T * p_clean，然后对 noisy 标签做交叉熵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a27e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_loss(p_clean, y, T):\n",
    "    p_tilde = p_clean @ T         \n",
    "    p_tilde = np.clip(p_tilde, 1e-12, 1.0)\n",
    "    return float(-np.log(p_tilde[np.arange(y.shape[0]), y]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225290ef",
   "metadata": {},
   "source": [
    "返回 dL/dz（对logits的梯度）。便于与线性层合成 dL/dW = X^T @ dL/dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e061503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dLdz_forward(p_clean, y, T):\n",
    "    N, C = p_clean.shape\n",
    "    Y = one_hot(y, C)\n",
    "    p_tilde = p_clean @ T\n",
    "    p_tilde = np.clip(p_tilde, 1e-12, 1.0)\n",
    "    dL_dp_tilde = -(Y / p_tilde) / N\n",
    "    dL_dp_clean = dL_dp_tilde @ T.T\n",
    "    s = (dL_dp_clean * p_clean).sum(axis=1, keepdims=True)\n",
    "    dL_dz = p_clean * (dL_dp_clean - s)\n",
    "    return dL_dz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b148e9",
   "metadata": {},
   "source": [
    "### 多类逻辑回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bee93966",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FwdCfg: wd:float=1e-4; max_iter:int=300; seed:int=42\n",
    "class SoftmaxFwd:\n",
    "    def __init__(self, D, C, T, cfg:FwdCfg):\n",
    "        self.D, self.C, self.T, self.cfg = D, C, T, cfg\n",
    "        set_seed(cfg.seed)\n",
    "        self.W = (0.01*np.random.randn(D,C)).astype(np.float64)\n",
    "    def _fun(self,w,X,y):\n",
    "        W=w.reshape(self.D,self.C); p=softmax(X@W)\n",
    "        base=forward_loss(p,y,self.T)\n",
    "        reg =0.5*self.cfg.wd*(sla.norm(W,'fro')**2)\n",
    "        dLdz=dLdz_forward(p,y,self.T)\n",
    "        grad = X.T@dLdz + self.cfg.wd*W\n",
    "        return base+reg, grad.reshape(-1)\n",
    "    def fit(self,X,y):\n",
    "        res=opt.minimize(self._fun,self.W.reshape(-1),args=(X,y),method=\"L-BFGS-B\",jac=True,\n",
    "                         options={\"maxiter\":self.cfg.max_iter})  # 不再传 disp，避免 warning\n",
    "        self.W=res.x.reshape(self.D,self.C); return res\n",
    "    def predict_proba(self,X): return softmax(X@self.W)\n",
    "    def predict(self,X): return self.predict_proba(X).argmax(1)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146ef5ab",
   "metadata": {},
   "source": [
    "### 调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a47c3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Result: cfg:FwdCfg; val_loss:float; test_acc:float\n",
    "def search_with_direction(Xtr, Str, Xts, Yts, T, seed=42):\n",
    "    # 预处理（用 train 部分的统计量）\n",
    "    Xtr_f = flatten(Xtr); Xts_f = flatten(Xts)\n",
    "    X_tr_raw, y_tr, X_val_raw, y_val = split(Xtr_f, Str, ratio=0.2, seed=seed)\n",
    "    std = fit_std(X_tr_raw)\n",
    "    X_tr = std.transform(X_tr_raw); X_val = std.transform(X_val_raw); X_te = std.transform(Xts_f)\n",
    "    D, C = X_tr.shape[1], T.shape[0]\n",
    "\n",
    "    # grid（只在优化/线代范围内改：wd、max_iter）\n",
    "    grid = [\n",
    "        FwdCfg(wd=1e-4, max_iter=500, seed=seed),\n",
    "        FwdCfg(wd=1e-3, max_iter=500, seed=seed),\n",
    "        FwdCfg(wd=5e-2, max_iter=500, seed=seed),\n",
    "        FwdCfg(wd=1e-2, max_iter=500, seed=seed),\n",
    "        FwdCfg(wd=5e-1, max_iter=500, seed=seed),\n",
    "        FwdCfg(wd=1e-1, max_iter=500, seed=seed),\n",
    "        \n",
    "    ]\n",
    "    results: List[Result] = []\n",
    "    for cfg in grid:\n",
    "        model = SoftmaxFwd(D, C, T, cfg)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        # 以 forward 验证损失选型\n",
    "        p_val = model.predict_proba(X_val)\n",
    "        vloss = forward_loss(p_val, y_val, T) + 0.5*cfg.wd*(sla.norm(model.W,'fro')**2)\n",
    "        # 在 clean test 上报 acc\n",
    "        test_acc = accuracy(Yts, model.predict(X_te))\n",
    "        results.append(Result(cfg, vloss, test_acc))\n",
    "\n",
    "    # 选最优（按 forward val loss）\n",
    "    best = min(results, key=lambda r: r.val_loss)\n",
    "    return best, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4739b0cb",
   "metadata": {},
   "source": [
    "## 四、main部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58519e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Dataset: datasets/FashionMNIST0.3.npz ====\n",
      "Tuned configs (both orientations):\n",
      "  [p@T] wd=0.0001, it=500 | val_loss=0.7299, test_acc=95.47%\n",
      "  [p@T] wd=0.001, it=500 | val_loss=0.6817, test_acc=96.23%\n",
      "  [p@T] wd=0.05, it=500 | val_loss=0.6749, test_acc=97.07%\n",
      "  [p@T] wd=0.01, it=500 | val_loss=0.6633, test_acc=97.47%\n",
      "  [p@T] wd=0.5, it=500 | val_loss=0.7295, test_acc=96.30%\n",
      "  [p@T] wd=0.1, it=500 | val_loss=0.6854, test_acc=96.93%\n",
      "** Best: [p@T] wd=0.01, it=500 | val_loss=0.6633, test_acc=97.47%\n",
      "\n",
      "==== Dataset: datasets/FashionMNIST0.6.npz ====\n",
      "Tuned configs (both orientations):\n",
      "  [p@T] wd=0.0001, it=500 | val_loss=1.1009, test_acc=72.17%\n",
      "  [p@T] wd=0.001, it=500 | val_loss=1.0996, test_acc=72.77%\n",
      "  [p@T] wd=0.05, it=500 | val_loss=1.0935, test_acc=95.13%\n",
      "  [p@T] wd=0.01, it=500 | val_loss=1.0943, test_acc=92.10%\n",
      "  [p@T] wd=0.5, it=500 | val_loss=1.0964, test_acc=92.83%\n",
      "  [p@T] wd=0.1, it=500 | val_loss=1.0941, test_acc=94.97%\n",
      "** Best: [p@T] wd=0.05, it=500 | val_loss=1.0935, test_acc=95.13%\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    set_seed(42)\n",
    "    datasets = [\n",
    "        \"datasets/FashionMNIST0.3.npz\",\n",
    "        \"datasets/FashionMNIST0.6.npz\",\n",
    "    ]\n",
    "    for path in datasets:\n",
    "        print(f\"\\n==== Dataset: {path} ====\")\n",
    "        T = get_T(path)\n",
    "        data = load_npz(path)\n",
    "        best, results = search_with_direction(data.Xtr, data.Str, data.Xts, data.Yts, T, seed=42)\n",
    "\n",
    "        def fmt(r:Result):\n",
    "            return f\"[p@T] wd={r.cfg.wd}, it={r.cfg.max_iter} | val_loss={r.val_loss:.4f}, test_acc={r.test_acc*100:.2f}%\"\n",
    "\n",
    "        print(\"Tuned configs (both orientations):\")\n",
    "        for r in results: print(\" \", fmt(r))\n",
    "        print(\"** Best:\", fmt(best))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba3825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
